---
source_txt: fullstack_samples/mlflow-master
converted_utc: 2025-12-18T11:25:53Z
part: 398
parts_total: 991
---

# FULLSTACK CODE DATABASE SAMPLES mlflow-master

## Verbatim Content (Part 398 of 991)

````text
================================================================================
FULLSTACK SAMPLES CODE DATABASE (VERBATIM) - mlflow-master
================================================================================
Generated: December 18, 2025
Source: fullstack_samples/mlflow-master
================================================================================

NOTES:
- This output is verbatim because the source is user-owned.
- Large/binary files may be skipped by size/binary detection limits.

================================================================================

---[FILE: mlflow_run.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_run.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/project-run.R
\name{mlflow_run}
\alias{mlflow_run}
\title{Run an MLflow Project}
\usage{
mlflow_run(
  uri = ".",
  entry_point = NULL,
  version = NULL,
  parameters = NULL,
  experiment_id = NULL,
  experiment_name = NULL,
  backend = NULL,
  backend_config = NULL,
  env_manager = NULL,
  storage_dir = NULL
)
}
\arguments{
\item{uri}{A directory containing modeling scripts, defaults to the current directory.}

\item{entry_point}{Entry point within project, defaults to `main` if not specified.}

\item{version}{Version of the project to run, as a Git commit reference for Git projects.}

\item{parameters}{A list of parameters.}

\item{experiment_id}{ID of the experiment under which to launch the run.}

\item{experiment_name}{Name of the experiment under which to launch the run.}

\item{backend}{Execution backend to use for run.}

\item{backend_config}{Path to JSON file which will be passed to the backend. For the Databricks backend,
it should describe the cluster to use when launching a run on Databricks.}

\item{env_manager}{If specified, create an environment for the project using the specified environment manager.
Available options are 'local', 'virtualenv', and 'conda'.}

\item{storage_dir}{Valid only when `backend` is local. MLflow downloads artifacts from distributed URIs passed to
parameters of type `path` to subdirectories of `storage_dir`.}
}
\value{
The run associated with this run.
}
\description{
Wrapper for the `mlflow run` CLI command. See
https://www.mlflow.org/docs/latest/cli.html#mlflow-run for more info.
}
\examples{
\dontrun{
# This parametrized script trains a GBM model on the Iris dataset and can be run as an MLflow
# project. You can run this script (assuming it's saved at /some/directory/params_example.R)
# with custom parameters via:
# mlflow_run(entry_point = "params_example.R", uri = "/some/directory",
#   parameters = list(num_trees = 200, learning_rate = 0.1))
install.packages("gbm")
library(mlflow)
library(gbm)
# define and read input parameters
num_trees <- mlflow_param(name = "num_trees", default = 200, type = "integer")
lr <- mlflow_param(name = "learning_rate", default = 0.1, type = "numeric")
# use params to fit a model
ir.adaboost <- gbm(Species ~., data=iris, n.trees=num_trees, shrinkage=lr)
}


}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_save_model.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_save_model.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-crate.R, R/model.R, R/model-h2o.R,
%   R/model-keras.R, R/model-xgboost.R
\name{mlflow_save_model.crate}
\alias{mlflow_save_model.crate}
\alias{mlflow_save_model}
\alias{mlflow_save_model.H2OModel}
\alias{mlflow_save_model.keras.engine.training.Model}
\alias{mlflow_save_model.xgb.Booster}
\title{Save Model for MLflow}
\usage{
\method{mlflow_save_model}{crate}(model, path, model_spec = list(), ...)

mlflow_save_model(model, path, model_spec = list(), ...)

\method{mlflow_save_model}{H2OModel}(model, path, model_spec = list(), conda_env = NULL, ...)

\method{mlflow_save_model}{keras.engine.training.Model}(model, path, model_spec = list(), conda_env = NULL, ...)

\method{mlflow_save_model}{xgb.Booster}(model, path, model_spec = list(), conda_env = NULL, ...)
}
\arguments{
\item{model}{The model that will perform a prediction.}

\item{path}{Destination path where this MLflow compatible model
will be saved.}

\item{model_spec}{MLflow model config this model flavor is being added to.}

\item{...}{Optional additional arguments.}

\item{conda_env}{Path to Conda dependencies file.}
}
\description{
Saves model in MLflow format that can later be used for prediction and serving. This method is
generic to allow package authors to save custom model types.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_search_experiments.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_search_experiments.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-experiments.R
\name{mlflow_search_experiments}
\alias{mlflow_search_experiments}
\title{Search Experiments}
\usage{
mlflow_search_experiments(
  filter = NULL,
  experiment_view_type = c("ACTIVE_ONLY", "DELETED_ONLY", "ALL"),
  max_results = 1000,
  order_by = list(),
  page_token = NULL,
  client = NULL
)
}
\arguments{
\item{filter}{A filter expression used to identify specific experiments.
The syntax is a subset of SQL which allows only ANDing together binary operations.
Examples: "attribute.name = 'MyExperiment'", "tags.problem_type = 'iris_regression'"}

\item{experiment_view_type}{Experiment view type. Only experiments matching this view type are
returned.}

\item{max_results}{Maximum number of experiments to retrieve.}

\item{order_by}{List of properties to order by. Example: "attribute.name".}

\item{page_token}{Pagination token to go to the next page based on a
previous query.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Search for experiments that satisfy specified criteria.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_search_registered_models.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_search_registered_models.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-registry.R
\name{mlflow_search_registered_models}
\alias{mlflow_search_registered_models}
\title{List registered models}
\usage{
mlflow_search_registered_models(
  filter = NULL,
  max_results = 100,
  order_by = list(),
  page_token = NULL,
  client = NULL
)
}
\arguments{
\item{filter}{A filter expression used to identify specific registered models.
The syntax is a subset of SQL which allows only ANDing together binary operations.
Example: "name = 'my_model_name' and tag.key = 'value1'"}

\item{max_results}{Maximum number of registered models to retrieve.}

\item{order_by}{List of registered model properties to order by. Example: "name".}

\item{page_token}{Pagination token to go to the next page based on a
previous query.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Retrieves a list of registered models.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_search_runs.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_search_runs.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-runs.R
\name{mlflow_search_runs}
\alias{mlflow_search_runs}
\title{Search Runs}
\usage{
mlflow_search_runs(
  filter = NULL,
  run_view_type = c("ACTIVE_ONLY", "DELETED_ONLY", "ALL"),
  experiment_ids = NULL,
  order_by = list(),
  client = NULL
)
}
\arguments{
\item{filter}{A filter expression over params, metrics, and tags, allowing returning a subset
of runs. The syntax is a subset of SQL which allows only ANDing together binary operations
between a param/metric/tag and a constant.}

\item{run_view_type}{Run view type.}

\item{experiment_ids}{List of string experiment IDs (or a single string experiment ID) to search
over. Attempts to use active experiment if not specified.}

\item{order_by}{List of properties to order by. Example: "metrics.acc DESC".}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Search for runs that satisfy expressions. Search expressions can use Metric and Param keys.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_server.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_server.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-server.R
\name{mlflow_server}
\alias{mlflow_server}
\title{Run MLflow Tracking Server}
\usage{
mlflow_server(
  file_store = "mlruns",
  default_artifact_root = NULL,
  host = "127.0.0.1",
  port = 5000,
  workers = NULL,
  static_prefix = NULL,
  serve_artifacts = FALSE
)
}
\arguments{
\item{file_store}{The root of the backing file store for experiment and run data.}

\item{default_artifact_root}{Local or S3 URI to store artifacts in, for newly created experiments.}

\item{host}{The network address to listen on (default: 127.0.0.1).}

\item{port}{The port to listen on (default: 5000).}

\item{workers}{Number of gunicorn worker processes to handle requests (default: 4).}

\item{static_prefix}{A prefix which will be prepended to the path of all static paths.}

\item{serve_artifacts}{A flag specifying whether or not to enable artifact serving (default: FALSE).}
}
\description{
Wrapper for `mlflow server`.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_set_experiment.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_set_experiment.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-experiments.R
\name{mlflow_set_experiment}
\alias{mlflow_set_experiment}
\title{Set Experiment}
\usage{
mlflow_set_experiment(
  experiment_name = NULL,
  experiment_id = NULL,
  artifact_location = NULL
)
}
\arguments{
\item{experiment_name}{Name of experiment to be activated.}

\item{experiment_id}{ID of experiment to be activated.}

\item{artifact_location}{Location where all artifacts for this experiment are stored. If
not provided, the remote server will select an appropriate default.}
}
\description{
Sets an experiment as the active experiment. Either the name or ID of the experiment can be provided.
  If the a name is provided but the experiment does not exist, this function creates an experiment
  with provided name. Returns the ID of the active experiment.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_set_experiment_tag.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_set_experiment_tag.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-experiments.R
\name{mlflow_set_experiment_tag}
\alias{mlflow_set_experiment_tag}
\title{Set Experiment Tag}
\usage{
mlflow_set_experiment_tag(key, value, experiment_id = NULL, client = NULL)
}
\arguments{
\item{key}{Name of the tag. All storage backends are guaranteed to support
key values up to 250 bytes in size. This field is required.}

\item{value}{String value of the tag being logged. All storage backends are
guaranteed to support key values up to 5000 bytes in size. This field is required.}

\item{experiment_id}{ID of the experiment.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Sets a tag on an experiment with the specified ID. Tags are experiment metadata that can be updated.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_set_model_version_tag.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_set_model_version_tag.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-registry.R
\name{mlflow_set_model_version_tag}
\alias{mlflow_set_model_version_tag}
\title{Set Model version tag}
\usage{
mlflow_set_model_version_tag(
  name,
  version = NULL,
  key = NULL,
  value = NULL,
  stage = NULL,
  client = NULL
)
}
\arguments{
\item{name}{Registered model name.}

\item{version}{Registered model version.}

\item{key}{Tag key to log. key is required.}

\item{value}{Tag value to log. value is required.}

\item{stage}{Registered model stage.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Set a tag for the model version.
When stage is set, tag will be set for latest model version of the stage.
Setting both version and stage parameter will result in error.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_set_tag.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_set_tag.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-runs.R
\name{mlflow_set_tag}
\alias{mlflow_set_tag}
\title{Set Tag}
\usage{
mlflow_set_tag(key, value, run_id = NULL, client = NULL)
}
\arguments{
\item{key}{Name of the tag. Maximum size is 255 bytes. This field is required.}

\item{value}{String value of the tag being logged. Maximum size is 500 bytes. This field is required.}

\item{run_id}{Run ID.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Sets a tag on a run. Tags are run metadata that can be updated during a run and
 after a run completes.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_set_tracking_uri.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_set_tracking_uri.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-globals.R
\name{mlflow_set_tracking_uri}
\alias{mlflow_set_tracking_uri}
\title{Set Remote Tracking URI}
\usage{
mlflow_set_tracking_uri(uri)
}
\arguments{
\item{uri}{The URI to the remote MLflow server.}
}
\description{
Specifies the URI to the remote MLflow server that will be used
to track experiments.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_source.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_source.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/project-source.R
\name{mlflow_source}
\alias{mlflow_source}
\title{Source a Script with MLflow Params}
\usage{
mlflow_source(uri)
}
\arguments{
\item{uri}{Path to an R script, can be a quoted or unquoted string.}
}
\description{
This function should not be used interactively. It is designed to be called via `Rscript` from
  the terminal or through the MLflow CLI.
}
\keyword{internal}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_start_run.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_start_run.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-runs.R
\name{mlflow_start_run}
\alias{mlflow_start_run}
\title{Start Run}
\usage{
mlflow_start_run(
  run_id = NULL,
  experiment_id = NULL,
  start_time = NULL,
  tags = NULL,
  client = NULL,
  nested = FALSE
)
}
\arguments{
\item{run_id}{If specified, get the run with the specified UUID and log metrics
and params under that run. The run's end time is unset and its status is set to
running, but the run's other attributes remain unchanged.}

\item{experiment_id}{Used only when `run_id` is unspecified. ID of the experiment under
which to create the current run. If unspecified, the run is created under
a new experiment with a randomly generated name.}

\item{start_time}{Unix timestamp of when the run started in milliseconds. Only used when `client` is specified.}

\item{tags}{Additional metadata for run in key-value pairs. Only used when `client` is specified.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}

\item{nested}{Controls whether the run to be started is nested in a parent run. `TRUE` creates a nest run.}
}
\description{
Starts a new run. If `client` is not provided, this function infers contextual information such as
  source name and version, and also registers the created run as the active run. If `client` is provided,
  no inference is done, and additional arguments such as `start_time` can be provided.
}
\examples{
\dontrun{
with(mlflow_start_run(), {
  mlflow_log_metric("test", 10)
})
}

}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_transition_model_version_stage.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_transition_model_version_stage.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-registry.R
\name{mlflow_transition_model_version_stage}
\alias{mlflow_transition_model_version_stage}
\title{Transition ModelVersion Stage}
\usage{
mlflow_transition_model_version_stage(
  name,
  version,
  stage,
  archive_existing_versions = FALSE,
  client = NULL
)
}
\arguments{
\item{name}{Name of the registered model.}

\item{version}{Model version number.}

\item{stage}{Transition `model_version` to this stage.}

\item{archive_existing_versions}{(Optional)}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Transition a model version to a different stage.
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_ui.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_ui.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/tracking-ui.R
\name{mlflow_ui}
\alias{mlflow_ui}
\title{Run MLflow User Interface}
\usage{
mlflow_ui(client, ...)
}
\arguments{
\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}

\item{...}{Optional arguments passed to `mlflow_server()` when `x` is a path to a file store.}
}
\description{
Launches the MLflow user interface.
}
\examples{
\dontrun{
library(mlflow)

# launch mlflow ui locally
mlflow_ui()

# launch mlflow ui for existing mlflow server
mlflow_set_tracking_uri("http://tracking-server:5000")
mlflow_ui()
}

}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_update_model_version.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_update_model_version.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-registry.R
\name{mlflow_update_model_version}
\alias{mlflow_update_model_version}
\title{Update model version}
\usage{
mlflow_update_model_version(name, version, description, client = NULL)
}
\arguments{
\item{name}{Name of the registered model.}

\item{version}{Model version number.}

\item{description}{Description of this model version.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Updates a model version
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow_update_registered_model.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/mlflow_update_registered_model.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/model-registry.R
\name{mlflow_update_registered_model}
\alias{mlflow_update_registered_model}
\title{Update a registered model}
\usage{
mlflow_update_registered_model(name, description, client = NULL)
}
\arguments{
\item{name}{The name of the registered model.}

\item{description}{The updated description for this registered model.}

\item{client}{(Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
If specified, MLflow will use the tracking server associated with the passed-in client. If
unspecified (the common case),
MLflow will use the tracking server associated with the current tracking URI.}
}
\description{
Updates a model in the Model Registry.
}
```

--------------------------------------------------------------------------------

---[FILE: reexports.Rd]---
Location: mlflow-master/mlflow/R/mlflow/man/reexports.Rd

```text
% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/imports.R
\docType{import}
\name{reexports}
\alias{reexports}
\alias{\%||\%}
\alias{\%>\%}
\alias{\%<-\%}
\title{Objects exported from other packages}
\keyword{internal}
\description{
These objects are imported from other packages. Follow the links
below to see their documentation.

\describe{
  \item{purrr}{\code{\link[purrr:pipe]{\%>\%}}}

  \item{rlang}{\code{\link[rlang:op-null-default]{\%||\%}}}

  \item{zeallot}{\code{\link[zeallot:operator]{\%<-\%}}}
}}
```

--------------------------------------------------------------------------------

---[FILE: roxlate-client.R]---
Location: mlflow-master/mlflow/R/mlflow/man-roxygen/roxlate-client.R

```text
#' @param client (Optional) An MLflow client object returned from \link[mlflow]{mlflow_client}.
#' If specified, MLflow will use the tracking server associated with the passed-in client. If
#' unspecified (the common case),
#' MLflow will use the tracking server associated with the current tracking URI.
```

--------------------------------------------------------------------------------

---[FILE: roxlate-model-uri.R]---
Location: mlflow-master/mlflow/R/mlflow/man-roxygen/roxlate-model-uri.R

```text
#' @param model_uri The location, in URI format, of the MLflow model.
#' @details The URI scheme must be supported by MLflow - i.e. there has to be an MLflow artifact
#'          repository corresponding to the scheme of the URI. The content is expected to point to a
#'          directory containing MLmodel. The following are examples of valid model uris:
#'
#'                  - ``file:///absolute/path/to/local/model``
#'                  - ``file:relative/path/to/local/model``
#'                  - ``s3://my_bucket/path/to/model``
#'                  - ``runs:/<mlflow_run_id>/run-relative/path/to/model``
#'                  - ``models:/<model_name>/<model_version>``
#'                  - ``models:/<model_name>/<stage>``
#'
#'  For more information about supported URI schemes, see the Artifacts Documentation at
#'  https://www.mlflow.org/docs/latest/tracking.html#artifact-stores.
```

--------------------------------------------------------------------------------

---[FILE: roxlate-run-id.R]---
Location: mlflow-master/mlflow/R/mlflow/man-roxygen/roxlate-run-id.R

```text
#' @param run_id Run ID.
```

--------------------------------------------------------------------------------

---[FILE: cast-utils.R]---
Location: mlflow-master/mlflow/R/mlflow/R/cast-utils.R

```text
# Cast utility functions to replace deprecated forge functions
# These functions use modern rlang/vctrs functions instead of deprecated ones

cast_string <- function(x, allow_na = FALSE) {
  if (is.null(x)) {
    if (allow_na) return(NA_character_) else stop("Value cannot be NULL")
  }
  if (is.na(x) && !allow_na) {
    stop("Value cannot be NA")
  }
  as.character(x)
}

cast_nullable_string <- function(x) {
  if (is.null(x)) return(NULL)
  as.character(x)
}

cast_scalar_double <- function(x, allow_na = FALSE) {
  if (is.null(x)) {
    if (allow_na) return(NA_real_) else stop("Value cannot be NULL")
  }
  if (length(x) != 1) {
    stop("Value must be a scalar (length 1)")
  }
  if (is.na(x) && !allow_na) {
    stop("Value cannot be NA")
  }
  as.numeric(x)
}

cast_nullable_scalar_double <- function(x) {
  if (is.null(x)) return(NULL)
  if (length(x) != 1) {
    stop("Value must be a scalar (length 1)")
  }
  as.numeric(x)
}

cast_nullable_scalar_integer <- function(x) {
  if (is.null(x)) return(NULL)
  if (length(x) != 1) {
    stop("Value must be a scalar (length 1)")
  }
  as.integer(x)
}

cast_string_list <- function(x) {
  if (is.null(x)) return(NULL)
  if (is.list(x)) {
    lapply(x, as.character)
  } else {
    as.list(as.character(x))
  }
}

cast_choice <- function(x, choices, allow_null = FALSE) {
  if (is.null(x)) {
    if (allow_null) return(NULL) else stop("Value cannot be NULL")
  }
  x <- as.character(x)
  if (!x %in% choices) {
    stop(sprintf("Value must be one of: %s", paste(choices, collapse = ", ")))
  }
  x
}
```

--------------------------------------------------------------------------------

---[FILE: cli.R]---
Location: mlflow-master/mlflow/R/mlflow/R/cli.R

```text
# Runs a generic MLflow command through the command-line interface.
#
# @param ... The parameters to pass to the command line.
# @param background Should this command be triggered as a background task?
#   Defaults to \code{FALSE}.
# @param echo Print the standard output and error to the screen? Defaults to
#   \code{TRUE}, does not apply to background tasks.
# @param stderr_callback \code{NULL} (the default), or a function to call for 
#   every chunk of the standard error, passed to \code{\link[=processx:run]{processx::run()}}.
# @param client MLflow client to provide environment for the cli process.
#
# @return A \code{processx} task.
#' @importFrom processx run
#' @importFrom processx process
#' @importFrom withr with_envvar
mlflow_cli <- function(...,
                       background = FALSE,
                       echo = TRUE,
                       stderr_callback = NULL,
                       client = mlflow_client()) {
  env <- if (is.null(client)) list() else client$get_cli_env()
  args <- list(...)
  verbose <- mlflow_is_verbose()
  python <- dirname(python_bin())
  mlflow_bin <- python_mlflow_bin()
  env <- modifyList(list(
    PATH = paste(python, Sys.getenv("PATH"), sep = ":"),
    MLFLOW_TRACKING_URI = mlflow_get_tracking_uri(),
    MLFLOW_BIN = mlflow_bin,
    MLFLOW_PYTHON_BIN = python_bin()
  ), env)
  MLFLOW_CONDA_HOME <- Sys.getenv("MLFLOW_CONDA_HOME", NA)
  if (!is.na(MLFLOW_CONDA_HOME)) {
    env$MLFLOW_CONDA_HOME <- MLFLOW_CONDA_HOME
  }
  with_envvar(env, {
    if (background) {
      result <- process$new(mlflow_bin, args = unlist(args), echo_cmd = verbose, supervise = TRUE)
    } else {
      result <- run(mlflow_bin, args = unlist(args), echo = echo, echo_cmd = verbose, stderr_callback = stderr_callback)
    }
  })
  invisible(result)
}

mlflow_cli_file_output <- function(response) {
  temp_file <- tempfile(fileext = ".txt")
  writeLines(response$stdout, temp_file)
  temp_file
}
```

--------------------------------------------------------------------------------

---[FILE: databricks-utils.R]---
Location: mlflow-master/mlflow/R/mlflow/R/databricks-utils.R

```text
# Utils for databricks authentication

new_mlflow_client.mlflow_databricks <- function(tracking_uri) {
  profile <- tracking_uri$path
  # make sure we can read the config
  new_mlflow_client_impl(
    get_host_creds = function() {
      get_databricks_config(profile)
    },
    get_cli_env = function() {
      databricks_config_as_env(get_databricks_config(profile))
    },
    class = "mlflow_databricks_client"
  )
}

DATABRICKS_CONFIG_FILE <- "DATABRICKS_CONFIG_FILE"
# map expected config variables to environment variables
config_variable_map <- list(
  host = "DATABRICKS_HOST",
  username = "DATABRICKS_USERNAME",
  password = "DATABRICKS_PASSWORD",
  token = "DATABRICKS_TOKEN",
  insecure = "DATABRICKS_INSECURE"
)

databricks_config_as_env <- function(config) {
  if (config$config_source != "cfgfile") { # pass the auth info via environment vars
    res <- config[!is.na(config)]
    res$config_source <- NULL
    if (!as.logical(res$insecure)) {
      res$insecure <- NULL
    }
    names(res) <- lapply(names(res), function (x) config_variable_map[[x]])
    res
  } else if (!is.na(Sys.getenv(DATABRICKS_CONFIG_FILE, NA))) {
    list(DATABRICKS_CONFIG_FILE = Sys.getenv(DATABRICKS_CONFIG_FILE))
  } else {
    # We do not need to do anything if the config comes from a file visible to both processes
    list()
  }
}

databricks_config_is_valid <- function(config) {
  !is.na(config$host) &&
      (!is.na(config$token) || (!is.na(config$username) && !is.na(config$password)))
}

#' @importFrom ini read.ini
get_databricks_config_for_profile <- function(profile) {
  config_path <- Sys.getenv("DATABRICKS_CONFIG_FILE", NA)
  config_path <- if (is.na(config_path)) path.expand("~/.databrickscfg") else config_path
  if (!file.exists(config_path)){
    stop(paste("Databricks configuration file is missing. Expected config file ", config_path))
  }
  config <- read.ini(config_path)
  if (!(profile %in% names(config))) {
    stop(paste("Missing profile '", profile, "'.", sep = ""))
  }
  new_databricks_config(config_source = "cfgfile", config[[profile]])
}

#' @importFrom utils modifyList
new_databricks_config <- function(config_source,
                                  config_vars) {
  res <- do.call(new_mlflow_host_creds, config_vars)
  res$config_source <- config_source
  res
}

get_databricks_config_from_env <- function() {
  config_vars <- lapply(config_variable_map, function(x) Sys.getenv(x, NA))
  names(config_vars) <- names(config_variable_map)
  new_databricks_config("env", config_vars)
}

get_databricks_config <- function(profile) {

  # If a profile is provided, fetch its configuration
  if (!is.na(profile)) {
    config <- get_databricks_config_for_profile(profile)
    if (databricks_config_is_valid(config)) {
      return(config)
    }
  }

  # Check for environment variables
  config <- get_databricks_config_from_env()
  if (databricks_config_is_valid(config)) {
    return(config)
  }

  # Check 'DEFAULT' profile
  config <- tryCatch({
    get_databricks_config_for_profile("DEFAULT")
  }, error = function(e) {
    # On error assume known invalid config
    list(host = NA, token = NA, username = NA, password = NA)
  })
  if (databricks_config_is_valid(config)) {
    return(config)
  }

  # When in Databricks (done last so other methods are explicit overrides)
  if (exists("spark.databricks.token", envir = .GlobalEnv) &&
      exists("spark.databricks.api.url", envir = .GlobalEnv)) {
    config_vars <- list(
      host = get("spark.databricks.api.url", envir = .GlobalEnv),
      token = get("spark.databricks.token", envir = .GlobalEnv),
      insecure = Sys.getenv(config_variable_map$insecure, "False")
    )
    config <- new_databricks_config(config_source = "db_dynamic", config_vars = config_vars)
    if (databricks_config_is_valid(config)) {
      return(config)
    }
  }

  # If no valid configuration is found by this point, raise an error
  stop("Could not find valid Databricks configuration.")
}

#' Get information from Databricks Notebook environment
#'
#' Retrieves the notebook id, path, url, name, version, and type from the Databricks Notebook
#' execution environment and sets them to a list to be used for setting the configured environment
#' for executing an MLflow run in R from Databricks.
#'
#' @param notebook_info The configuration data from the Databricks Notebook environment
#'
#' @return A list of tags to be set by the run context when creating MLflow runs in the
#' current Databricks Notebook environment
build_context_tags_from_databricks_notebook_info <- function(notebook_info) {
  tags <- list()
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_NOTEBOOK_ID]] <- notebook_info$id
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_NOTEBOOK_PATH]] <- notebook_info$path
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_WEBAPP_URL]] <- notebook_info$webapp_url
  tags[[MLFLOW_TAGS$MLFLOW_SOURCE_NAME]] <- notebook_info$path
  tags[[MLFLOW_TAGS$MLFLOW_SOURCE_VERSION]] <- get_source_version()
  tags[[MLFLOW_TAGS$MLFLOW_SOURCE_TYPE]] <- MLFLOW_SOURCE_TYPE$NOTEBOOK
  tags
}

#' Get information from a Databricks job execution context
#'
#' Parses the data from a job execution context when running on Databricks in a non-interactive
#' mode. This function extracts relevant data that MLflow needs in order to properly utilize the
#' MLflow APIs from this context.
#'
#' @param job_info The job-related metadata from a running Databricks job
#'
#' @return A list of tags to be set by the run context when creating MLflow runs in the
#' current Databricks Job environment
build_context_tags_from_databricks_job_info <- function(job_info) {
  tags <- list()
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_JOB_ID]] <- job_info$job_id
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_JOB_RUN_ID]] <- job_info$run_id
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_JOB_TYPE]] <- job_info$job_type
  tags[[MLFLOW_DATABRICKS_TAGS$MLFLOW_DATABRICKS_WEBAPP_URL]] <- job_info$webapp_url
  tags[[MLFLOW_TAGS$MLFLOW_SOURCE_NAME]] <- paste(
    "jobs", job_info$job_id, "run", job_info$run_id, sep = "/"
  )
  tags[[MLFLOW_TAGS$MLFLOW_SOURCE_VERSION]] <- get_source_version()
  tags[[MLFLOW_TAGS$MLFLOW_SOURCE_TYPE]] <- MLFLOW_SOURCE_TYPE$JOB
  tags
}

# Helper function to delegate to the next method in the S3 dispatch chain
# This wrapper makes it possible to test delegation behavior
mlflow_databricks_delegate_to_next_method <- function() {
  NextMethod()
}

mlflow_get_run_context.mlflow_databricks_client <- function(client, experiment_id, ...) {
  if (exists(".databricks_internals")) {
    databricks_internal_env <- get(".databricks_internals", envir = .GlobalEnv)
    notebook_info <- do.call(".get_notebook_info", list(), envir = databricks_internal_env)
    if (!is.na(notebook_info$id) && !is.na(notebook_info$path)) {
      return(list(
        client = client,
        tags = build_context_tags_from_databricks_notebook_info(notebook_info),
        experiment_id = experiment_id %||% notebook_info$id,
        ...
      ))
    }

    job_info <- if (exists(".get_job_info", envir = databricks_internal_env)) {
      do.call(".get_job_info", list(), envir = databricks_internal_env)
    } else {
      NA
    }
    if (!all(is.na(job_info)) && !is.na(job_info$job_id)) {
      return(list(
        client = client,
        tags = build_context_tags_from_databricks_job_info(job_info),
        experiment_id = experiment_id %||% 0,
        ...
      ))
    }
    mlflow_databricks_delegate_to_next_method()
  } else {
    mlflow_databricks_delegate_to_next_method()
  }
}

MLFLOW_DATABRICKS_TAGS <- list(
  MLFLOW_DATABRICKS_NOTEBOOK_ID = "mlflow.databricks.notebookID",
  MLFLOW_DATABRICKS_NOTEBOOK_PATH = "mlflow.databricks.notebookPath",
  MLFLOW_DATABRICKS_WEBAPP_URL = "mlflow.databricks.webappURL",
  MLFLOW_DATABRICKS_RUN_URL = "mlflow.databricks.runURL",
  # The SHELL_JOB_ID and SHELL_JOB_RUN_ID tags are used for tracking the
  # Databricks Job ID and Databricks Job Run ID associated with an MLflow Project run
  MLFLOW_DATABRICKS_SHELL_JOB_ID = "mlflow.databricks.shellJobID",
  MLFLOW_DATABRICKS_SHELL_JOB_RUN_ID = "mlflow.databricks.shellJobRunID",
  # The JOB_ID, JOB_RUN_ID, and JOB_TYPE tags are used for automatically recording Job
  # information when MLflow Tracking APIs are used within a Databricks Job
  MLFLOW_DATABRICKS_JOB_ID = "mlflow.databricks.jobID",
  MLFLOW_DATABRICKS_JOB_RUN_ID = "mlflow.databricks.jobRunID",
  MLFLOW_DATABRICKS_JOB_TYPE = "mlflow.databricks.jobType"
)
```

--------------------------------------------------------------------------------

---[FILE: globals.R]---
Location: mlflow-master/mlflow/R/mlflow/R/globals.R

```text
.globals <- new.env(parent = emptyenv())
```

--------------------------------------------------------------------------------

---[FILE: imports.R]---
Location: mlflow-master/mlflow/R/mlflow/R/imports.R

```text
#' @importFrom rlang %||%
rlang::`%||%`

#' @importFrom purrr %>%
purrr::`%>%`

#' @importFrom zeallot %<-%
zeallot::`%<-%`
```

--------------------------------------------------------------------------------

---[FILE: logging.R]---
Location: mlflow-master/mlflow/R/mlflow/R/logging.R

```text
mlflow_is_verbose <- function() {
  nchar(Sys.getenv("MLFLOW_VERBOSE")) > 0 || getOption("mlflow.verbose", FALSE)
}

mlflow_verbose_message <- function(...) {
  if (mlflow_is_verbose()) {
    message(...)
  }
}
```

--------------------------------------------------------------------------------

---[FILE: mlflow-package.R]---
Location: mlflow-master/mlflow/R/mlflow/R/mlflow-package.R

```text
#' @keywords internal
"_PACKAGE"

# The following block is used by usethis to automatically manage
# roxygen namespace tags. Modify with care!
## usethis namespace: start
## usethis namespace: end
if (getRversion() >= "2.15.1") {
  utils::globalVariables(".")
}
```

--------------------------------------------------------------------------------

---[FILE: model-crate.R]---
Location: mlflow-master/mlflow/R/mlflow/R/model-crate.R

```text
#' @rdname mlflow_save_model
#' @export
mlflow_save_model.crate <- function(model, path, model_spec=list(), ...) {
  if (dir.exists(path)) unlink(path, recursive = TRUE)
  dir.create(path)

  serialized <- serialize(model, NULL)

  saveRDS(
    serialized,
    file.path(path, "crate.bin")
  )

  model_spec$flavors <- append(model_spec$flavors, list(
    crate = list(
      version = "0.1.0",
      model = "crate.bin"
    )
  ))
  mlflow_write_model_spec(path, model_spec)
  model_spec
}

#' @export
mlflow_load_flavor.mlflow_flavor_crate <- function(flavor, model_path) {
  unserialize(readRDS(file.path(model_path, "crate.bin")))
}

#' @export
mlflow_predict.crate <- function(model, data, ...) {
  do.call(model, list(data, ...))
}
```

--------------------------------------------------------------------------------

````
