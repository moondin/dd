---
source_txt: fullstack_samples/mlflow-master
converted_utc: 2025-12-18T11:25:52Z
part: 6
parts_total: 991
---

# FULLSTACK CODE DATABASE SAMPLES mlflow-master

## Verbatim Content (Part 6 of 991)

````text
================================================================================
FULLSTACK SAMPLES CODE DATABASE (VERBATIM) - mlflow-master
================================================================================
Generated: December 18, 2025
Source: fullstack_samples/mlflow-master
================================================================================

NOTES:
- This output is verbatim because the source is user-owned.
- Large/binary files may be skipped by size/binary detection limits.

================================================================================

---[FILE: pyproject.toml]---
Location: mlflow-master/pyproject.toml
Signals: Docker

```toml
# Auto-generated by dev/pyproject.py. Do not edit manually.
# This file defines the package metadata of `mlflow` **during development**. To install `mlflow`
# from the source code, `mlflow-skinny` and `mlflow-tracing` are NOT included in the requirements.
# This file will be replaced by `pyproject.release.toml` when releasing a new version.

[build-system]
requires = ["setuptools"]
build-backend = "setuptools.build_meta"

[project]
name = "mlflow"
version = "3.8.1.dev0"
description = "MLflow is an open source platform for the complete machine learning lifecycle"
readme = "README.md"
keywords = ["mlflow", "ai", "databricks"]
classifiers = [
  "Development Status :: 5 - Production/Stable",
  "Intended Audience :: Developers",
  "Intended Audience :: End Users/Desktop",
  "Intended Audience :: Science/Research",
  "Intended Audience :: Information Technology",
  "Topic :: Scientific/Engineering :: Artificial Intelligence",
  "Topic :: Software Development :: Libraries :: Python Modules",
  "License :: OSI Approved :: Apache Software License",
  "Operating System :: OS Independent",
  "Programming Language :: Python :: 3.10",
]
requires-python = ">=3.10"
dependencies = [
  "Flask-CORS<7",
  "Flask<4",
  "alembic<2,!=1.10.0",
  "cachetools<7,>=5.0.0",
  "click<9,>=7.0",
  "cloudpickle<4",
  "cryptography<47,>=43.0.0",
  "databricks-sdk<1,>=0.20.0",
  "docker<8,>=4.0.0",
  "fastapi<1",
  "gitpython<4,>=3.1.9",
  "graphene<4",
  "gunicorn<24; platform_system != 'Windows'",
  "huey<3,>=2.5.0",
  "importlib_metadata<9,>=3.7.0,!=4.7.0",
  "matplotlib<4",
  "numpy<3",
  "opentelemetry-api<3,>=1.9.0",
  "opentelemetry-proto<3,>=1.9.0",
  "opentelemetry-sdk<3,>=1.9.0",
  "packaging<26",
  "pandas<3",
  "protobuf<7,>=3.12.0",
  "pyarrow<23,>=4.0.0",
  "pydantic<3,>=2.0.0",
  "python-dotenv<2,>=0.19.0",
  "pyyaml<7,>=5.1",
  "requests<3,>=2.17.3",
  "scikit-learn<2",
  "scipy<2",
  "sqlalchemy<3,>=1.4.0",
  "sqlparse<1,>=0.4.0",
  "typing-extensions<5,>=4.0.0",
  "uvicorn<1",
  "waitress<4; platform_system == 'Windows'",
]
[[project.maintainers]]
name = "Databricks"
email = "mlflow-oss-maintainers@googlegroups.com"

[project.license]
file = "LICENSE.txt"

[project.optional-dependencies]
extras = [
  "pyarrow",
  "requests-auth-aws-sigv4",
  "boto3",
  "botocore",
  "google-cloud-storage>=1.30.0",
  "azureml-core>=1.2.0",
  "pysftp",
  "kubernetes",
  "virtualenv",
  "prometheus-flask-exporter",
]
databricks = [
  "azure-storage-file-datalake>12",
  "google-cloud-storage>=1.30.0",
  "boto3>1",
  "botocore",
  "databricks-agents>=1.2.0,<2.0",
]
mlserver = [
  "mlserver>=1.2.0,!=1.3.1,<2.0.0",
  "mlserver-mlflow>=1.2.0,!=1.3.1,<2.0.0",
]
gateway = [
  "aiohttp<4",
  "boto3<2,>=1.28.56",
  "fastapi<1",
  "slowapi<1,>=0.1.9",
  "tiktoken<1",
  "uvicorn[standard]<1",
  "watchfiles<2",
]
genai = [
  "aiohttp<4",
  "boto3<2,>=1.28.56",
  "fastapi<1",
  "litellm<2,>=1.0.0",
  "slowapi<1,>=0.1.9",
  "tiktoken<1",
  "uvicorn[standard]<1",
  "watchfiles<2",
]
mcp = ["fastmcp<3,>=2.0.0", "click!=8.3.0"]
sqlserver = ["mlflow-dbstore"]
aliyun-oss = ["aliyunstoreplugin"]
jfrog = ["mlflow-jfrog-plugin"]
langchain = ["langchain>=0.3.12,<=1.1.3"]
auth = ["Flask-WTF<2"]

[project.urls]
homepage = "https://mlflow.org"
issues = "https://github.com/mlflow/mlflow/issues"
documentation = "https://mlflow.org/docs/latest"
repository = "https://github.com/mlflow/mlflow"

[project.scripts]
mlflow = "mlflow.cli:cli"

[project.entry-points."mlflow.app"]
basic-auth = "mlflow.server.auth:create_app"

[project.entry-points."mlflow.app.client"]
basic-auth = "mlflow.server.auth.client:AuthServiceClient"

[project.entry-points."mlflow.deployments"]
databricks = "mlflow.deployments.databricks"
http = "mlflow.deployments.mlflow"
https = "mlflow.deployments.mlflow"
openai = "mlflow.deployments.openai"

[tool.setuptools.package-data]
mlflow = [
  "store/db_migrations/alembic.ini",
  "temporary_db_migrations_for_pre_1_users/alembic.ini",
  "pyspark/ml/log_model_allowlist.txt",
  "server/auth/basic_auth.ini",
  "server/auth/db/migrations/alembic.ini",
  "models/notebook_resources/**/*",
  "ai_commands/**/*.md",
  "models/container/**/*",
  "server/js/build/**/*",
]

[tool.setuptools.packages.find]
where = ["."]
include = ["mlflow", "mlflow.*"]
exclude = ["tests", "tests.*"]
namespaces = false

# Package metadata: can't be updated manually, use dev/pyproject.py
# -----------------------------------------------------------------
# Dev tool settings: can be updated manually

[dependency-groups]
dev = [
  { include-group = "lint" },
  { include-group = "test" },
  { include-group = "build" },
  "mlflow-test-plugin",
]
lint = [
  "ruff==0.12.10",
  "black==23.7.0",
  "blacken-docs==1.18.0",
  "pre-commit==4.0.1",
  "toml==0.10.2",
  "mypy==1.17.1",
  "pydantic>=2.0",
  "clint",
  "pyyaml>=6.0.2",
  "packaging>=25.0",
]
test = [
  "pytest==8.4.0",
  "pytest-asyncio",
  "pytest-repeat",
  "pytest-cov",
  "pytest-timeout",
  "psutil",
  "pyspark",
  "opentelemetry-exporter-otlp-proto-grpc",
  "opentelemetry-exporter-otlp-proto-http",
]
build = ["pip", "setuptools", "wheel", "build"]
docs = [
  "sphinx==4.2.0",
  "sphinx-autobuild",
  "sphinx-click",
  "sphinx-tabs==3.2.0",
  "sphinx-reredirects==0.1.3",
  "sphinxcontrib-applehelp<1.0.8",
  "sphinxcontrib-devhelp<1.0.6",
  "sphinxcontrib-htmlhelp<2.0.4",
  "sphinxcontrib-serializinghtml<1.1.10",
  "sphinxcontrib-qthelp<1.0.7",
  "nbconvert",
  "nbformat",
  "tensorflow",
  "keras",
  "pyspark",
  "datasets",
  "plotly",
  "torch>=1.11.0",
  # TODO: Unpin once https://github.com/astral-sh/uv/issues/16386 is resolved
  "torchvision>=0.12.0,<0.24.0",
  "lightning>=1.8.1",
  "Flask-WTF<2",
  "polars>=1",
  "openai",
  "haystack-ai",
  "deepeval",
]

[tool.uv]
required-version = "==0.9.8"
constraint-dependencies = [
  # xgboost 3.1.0 changed base_score format to vector for multi-output models, breaking shap compatibility
  # https://xgboost.readthedocs.io/en/latest/changes/v3.1.0.html#multi-target-class-intercept
  "xgboost<3.1.0",
  # pyspark 4.1.0 causes issues with documentation build
  "pyspark<4.1.0",
]
exclude-dependencies = ["databricks-connect"]

[tool.uv.pip]
torch-backend = "cpu"

[tool.uv.workspace]
members = ["dev/clint", "tests/resources/mlflow-test-plugin"]

[tool.uv.sources]
clint = { workspace = true }
mlflow-test-plugin = { workspace = true }
torch = { index = "pytorch-cpu" }
torchvision = { index = "pytorch-cpu" }

[[tool.uv.index]]
name = "pytorch-cpu"
url = "https://download.pytorch.org/whl/cpu"
explicit = true

[tool.ruff]
line-length = 100
target-version = "py310"
required-version = "0.12.10"
force-exclude = true
extend-include = ["*.ipynb"]
extend-exclude = [
  "examples/llama_index/workflow",
  "mlflow/protos",
  "mlflow/ml_package_versions.py",
  "mlflow/server/graphql/autogenerated_graphql_schema.py",
  "mlflow/server/js",
  "tests/protos",
]

[tool.ruff.format]
docstring-code-format = true
docstring-code-line-length = 88

[tool.ruff.lint]
preview = true
dummy-variable-rgx = "^(_+|(_+[a-zA-Z0-9_]*[a-zA-Z0-9]+?))$"
select = [
  "B006",    # multiple-argument-default
  "B012",    # jump-statement-in-finally
  "B015",    # useless-comparison
  "D209",    # new-line-after-last-paragraph
  "D411",    # no-blank-line-before-section
  "DTZ003",  # call-datetime-utcnow
  "E",       # error
  "F",       # Pyflakes
  "FURB110", # if-exp-instead-of-or-operator
  "FURB129", # readlines-in-for
  "FURB142", # for-loop-set-mutations
  "FURB148", # unnecessary-enumerate
  "FURB167", # regex-flag-alias
  "FURB188", # slice-to-remove-prefix-or-suffix
  "FURB192", # sorted-min-max
  "C4",      # flake8-comprehensions
  "I",       # isort
  "ISC001",  # single-line-implicit-string-concatenation
  "N804",    # invalid-first-argument-name-for-class-method
  "PERF401", # manual-list-comprehension
  "PIE790",  # unnecessary-placeholder
  "PLR0402", # manual-from-import
  "PLR1714", # repeated-equality-comparison
  "PLE1205", # logging-too-many-args
  "PLW0602", # global-variable-not-assigned
  "PLW1508", # invalid-envvar-default
  "PT001",   # pytest-fixture-incorrect-parentheses-style
  "PT002",   # pytest-fixture-positional-args
  "PT003",   # pytest-extraneous-scope-function
  "PT006",   # pytest-parameterize-names-wrong-type
  "PT007",   # pytest-parameterize-values-wrong-type
  "PT009",   # pytest-unittest-assertion
  "PT010",   # pytest-raises-without-exception
  "PT011",   # pytest-raises-too-broad
  "PT012",   # pytest-raises-with-multiple-statements
  "PT013",   # pytest-incorrect-pytest-import
  "PT014",   # pytest-duplicate-parametrize-test-cases
  "PT018",   # pytest-composite-assertion
  "PT022",   # pytest-useless-yield-fixture
  "PT023",   # pytest-incorrect-mark-parentheses-style
  "PT026",   # pytest-use-fixtures-without-parameters
  "PT027",   # pytest-unittest-raises-assertion
  "PT030",   # pytest-warns-too-broad
  "PT031",   # pytest-warns-with-multiple-statements
  "PYI024",  # collections-named-tuple
  "RET504",  # unnecessary-assign
  "RUF002",  # ambiguous-unicode-character-docstring
  "RUF003",  # ambiguous-unicode-character-comment
  "RUF010",  # explicit-f-string-type-conversion
  "RUF013",  # implicit-optional
  "RUF039",  # unraw-re-pattern
  "RUF051",  # if-key-in-dict-del
  "RUF100",  # unused-noqa
  "S102",    # exec-builtin
  "S307",    # suspicious-eval-usage
  "S324",    # hashlib-insecure-hash-function
  "S506",    # unsafe-yaml-load
  "SIM101",  # duplicate-isinstance-call
  "SIM108",  # if-else-block-instead-of-if-exp
  "SIM114",  # if-with-same-arms
  "SIM115",  # open-file-with-context-handler
  "SIM210",  # if-expr-with-true-false
  "SIM910",  # dict-get-with-none-default
  "T20",     # flake8-print
  "TID251",  # banned-api
  "TID252",  # relative-import
  "TRY203",  # useless-try-except
  "UP004",   # useless-object-inheritance
  "UP006",   # non-pep585-annotation
  "UP007",   # non-pep604-annotation-union
  "UP008",   # super-call-with-parameters
  "UP011",   # lru-cache-without-parameters
  "UP012",   # unnecessary-encode-utf8
  "UP015",   # redundant-open-modes
  "UP030",   # format-literals
  "UP031",   # printf-string-format
  "UP034",   # extraneous-parenthesis
  "UP045",   # non-pep604-annotation-optional
  "W",       # warning
]
ignore = [
  "E265", # no-space-after-block-comment
  "E266", # multiple-leading-hashes-for-block-comment
  "E402", # module-import-not-at-top-of-file
  "E721", # type-comparison
  "E741", # ambiguous-variable-name
  "F811", # redefined-while-unused
]

[tool.ruff.lint.per-file-ignores]
"dev/*" = ["T201", "PT018"]
"examples/*" = ["T20", "RET504", "E501"]
"docs/*" = ["T20", "RET504", "E501"]
"mlflow/*" = ["PT018"]

[tool.ruff.lint.flake8-pytest-style]
mark-parentheses = false
fixture-parentheses = false
raises-require-match-for = ["*"]
warns-require-match-for = ["*"]

[tool.ruff.lint.flake8-tidy-imports]
ban-relative-imports = "all"

[tool.ruff.lint.isort]
forced-separate = ["tests"]
# https://docs.astral.sh/ruff/faq/#how-does-ruff-determine-which-of-my-imports-are-first-party-third-party-etc
# The `docker` package is marked as third-party because a `docker` directory exists in the repository root,
# which would otherwise cause ruff to incorrectly classify it as first-party.
known-third-party = ["docker"]

[tool.ruff.lint.flake8-tidy-imports.banned-api]
"pkg_resources".msg = "Do not use pkg_resources. Use importlib.resources or importlib.metadata instead."
"entrypoints".msg = "Do not use entrypoints. Use importlib.metadata.entry_points instead."
"pip".msg = "Importing pip can cause undesired side effects such as https://github.com/scikit-learn/scikit-learn/issues/26992. Consider using `subprocess.run([sys.executable, '-m', 'pip', ...])` instead."

[tool.ruff.lint.pydocstyle]
convention = "google"

[tool.clint]
exclude = [
  "mlflow/protos",
  "mlflow/ml_package_versions.py",
  "mlflow/models/notebook_resources/eval_with_synthetic_example.py",
  "mlflow/server/js",
  "mlflow/store/db_migrations",
  "mlflow/genai/__init__.py",
  "mlflow/genai/datasets/__init__.py",
  "mlflow/genai/labeling/__init__.py",
  "mlflow/genai/label_schemas/__init__.py",
  "tests/protos",
  "docs/docs/classic-ml/mlflow-3/index.mdx",
]
typing-extensions-allowlist = [
  # Docs: https://typing-extensions.readthedocs.io/en/latest/
  "typing_extensions.Self",        # Added in 4.0.0
  "typing_extensions.NotRequired", # Added in 4.0.0
]
# Rules that are only enabled for code examples.
example-rules = [
  "lazy-builtin-import",
  "log-model-artifact-path",
  "unknown-mlflow-function",
  "unknown-mlflow-arguments",
  "multi-assign",
  "get-artifact-uri",
]

[tool.clint.per-file-ignores]
# Rules that should only be enabled for files in the root mlflow directory
"^(?!mlflow/).*$" = [
  "forbidden-set-active-model-usage",
  "unnamed-thread",
  "thread-pool-executor-without-thread-name-prefix",
]
# Multi-assign has better readability in this example.
"docs/docs/classic-ml/getting-started/deep-learning.mdx" = ["multi-assign"]

[tool.clint.forbidden-top-level-imports]
"mlflow/gateway/providers/*" = ["fastapi", "starlette", "aiohttp"]
# Databricks SDK/Agents should not be imported at the top level
"mlflow/*" = ["databricks"]

# typos
[tool.typos.default.extend-words]
als = "als"                        # alternating least squares
mape = "mape"                      # mean absolute percentage error
fpr = "fpr"                        # false positive rate
gam = "gam"                        # generalized additive models
ser = "ser"                        # serialization
yhat = "yhat"                      # ≈∑
iternal = "internal"               # typo of "internal"
instumentation = "instrumentation" # typo of "instrumentation"
selectin = "selectin"              # SQLAlchemy lazy loading strategy
tpe = "tpe"                        # Tree-structured Parzen Estimator (hyperopt/optuna)
TPE = "TPE"                        # Tree-structured Parzen Estimator (hyperopt/optuna)
indx = "indx"                      # intentional shorthand for index

# https://github.com/crate-ci/typos/blob/master/docs/reference.md
[tool.typos.files]
extend-exclude = [
  # Ignore proto files
  "mlflow/protos/**/*",
  # Vendored files
  "mlflow/utils/gorilla.py",
]

[tool.typos.default]
extend-ignore-re = [
  # Line ignore with trailing `# spellchecker: disable-line`
  "(?Rm)^.*#\\s*spellchecker: disable-line$",
  # Line block with `# spellchecker: <on|off>`
  "(?s)(#|//)\\s*spellchecker: off.*?\\n\\s*(#|//)\\s*spellchecker: on",
  # numpy.arange
  "(?i)(numpy|np)\\.arange",
  # nd array
  "(?i)nd( |_|\\.)?array",
  "aNothEr",
  # German / French words/sentences used for testing
  "MLflow ist",
  "Ich habe eine sch√∂ne Haufe von Kokos",
  "Ich bin das Modell eines modernen General",
  "Apple Inc. ist ein",
  "Apple Inc. est une entreprise technologique",
  # pytorch-lightning
  "lightning",
  # `typos` flags 'lok' as a typo of 'look'
  "(?i)daniel lok",
  # GitHub user mentions
  "@[a-z0-9-]+",
  "PNGs",
  # Azure Container Instances
  "\\(ACI\\)",
  # Azure Kubernetes Service
  "\\(AKS\\)",
  "AKS",
  # Song lyrics - "Don't Stop Believin'" by Journey
  "livin'",
]

[tool.pytest.ini_options]
addopts = "-p no:legacypath --strict-markers --color=yes --durations=10 --showlocals -v"
filterwarnings = [
  # Prevent deprecated numpy type aliases from being used
  "error:^`np\\.[a-z]+` is a deprecated alias for.+:DeprecationWarning:mlflow",
  "error:^`np\\.[a-z]+` is a deprecated alias for.+:DeprecationWarning:tests",
  "error::pytest.PytestCollectionWarning",
  "error:.*type should be str.*converted to str implicitly:pytest.PytestWarning",
  # Prevent deprecated threading.Thread.getName() from being used
  "error:getName\\(\\) is deprecated, get the name attribute instead:DeprecationWarning",
  # Prevent deprecated non-integer arguments to randrange() from being used
  "error:non-integer arguments to randrange\\(\\) have been deprecated:DeprecationWarning",
  # Prevent usage of deprecated Pydantic v2.0 features
  "error::pydantic.PydanticDeprecatedSince20:mlflow",
  "error::pydantic.PydanticDeprecatedSince20:tests",
  # Silence filesystem backend deprecation warnings (https://github.com/mlflow/mlflow/issues/18534)
  "ignore:The filesystem (tracking|model registry) backend.*will be deprecated:FutureWarning",
]
timeout = 1200

# Currently, type checking is only enabled for `dev/clint`.
[tool.mypy]
python_version = "3.10"
disallow_untyped_defs = true
exclude_gitignore = true
```

--------------------------------------------------------------------------------

---[FILE: README.md]---
Location: mlflow-master/README.md

```text
<h1 align="center" style="border-bottom: none">
    <a href="https://mlflow.org/">
        <img alt="MLflow logo" src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/logo.svg" width="200" />
    </a>
</h1>
<h2 align="center" style="border-bottom: none">Open-Source Platform for Productionizing AI</h2>

MLflow is an open-source developer platform to build AI/LLM applications and models with confidence. Enhance your AI applications with end-to-end **experiment tracking**, **observability**, and **evaluations**, all in one integrated platform.

<div align="center">

[![Python SDK](https://img.shields.io/pypi/v/mlflow)](https://pypi.org/project/mlflow/)
[![PyPI Downloads](https://img.shields.io/pypi/dm/mlflow)](https://pepy.tech/projects/mlflow)
[![License](https://img.shields.io/github/license/mlflow/mlflow)](https://github.com/mlflow/mlflow/blob/main/LICENSE)
<a href="https://twitter.com/intent/follow?screen_name=mlflow" target="_blank">
<img src="https://img.shields.io/twitter/follow/mlflow?logo=X&color=%20%23f5f5f5"
      alt="follow on X(Twitter)"></a>
<a href="https://www.linkedin.com/company/mlflow-org/" target="_blank">
<img src="https://custom-icon-badges.demolab.com/badge/LinkedIn-0A66C2?logo=linkedin-white&logoColor=fff"
      alt="follow on LinkedIn"></a>
[![Ask DeepWiki](https://deepwiki.com/badge.svg)](https://deepwiki.com/mlflow/mlflow)

</div>

<div align="center">
   <div>
      <a href="https://mlflow.org/"><strong>Website</strong></a> ¬∑
      <a href="https://mlflow.org/docs/latest"><strong>Docs</strong></a> ¬∑
      <a href="https://github.com/mlflow/mlflow/issues/new/choose"><strong>Feature Request</strong></a> ¬∑
      <a href="https://mlflow.org/blog"><strong>News</strong></a> ¬∑
      <a href="https://www.youtube.com/@mlflowoss"><strong>YouTube</strong></a> ¬∑
      <a href="https://lu.ma/mlflow?k=c"><strong>Events</strong></a>
   </div>
</div>

<br>

## üöÄ Installation

To install the MLflow Python package, run the following command:

```
pip install mlflow
```

## üì¶ Core Components

MLflow is **the only platform that provides a unified solution for all your AI/ML needs**, including LLMs, Agents, Deep Learning, and traditional machine learning.

### üí° For LLM / GenAI Developers

<table>
  <tr>
    <td>
    <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-tracing.png" alt="Tracing" width=100%>
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/llms/tracing/index.html"><strong>üîç Tracing / Observability</strong></a>
        <br><br>
        <div>Trace the internal states of your LLM/agentic applications for debugging quality issues and monitoring performance with ease.</div><br>
        <a href="https://mlflow.org/docs/latest/genai/tracing/quickstart/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
    <td>
    <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-llm-eval.png" alt="LLM Evaluation" width=100%>
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/genai/eval-monitor/"><strong>üìä LLM Evaluation</strong></a>
        <br><br>
        <div>A suite of automated model evaluation tools, seamlessly integrated with experiment tracking to compare across multiple versions.</div><br>
        <a href="https://mlflow.org/docs/latest/genai/eval-monitor/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-prompt.png" alt="Prompt Management">
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/prompt-registry/"><strong>ü§ñ Prompt Management</strong></a>
        <br><br>
        <div>Version, track, and reuse prompts across your organization, helping maintain consistency and improve collaboration in prompt development.</div><br>
        <a href="https://mlflow.org/docs/latest/genai/prompt-registry/create-and-edit-prompts/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
    <td>
      <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-logged-model.png" alt="MLflow Hero">
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/genai/prompt-version-mgmt/version-tracking/"><strong>üì¶ App Version Tracking</strong></a>
        <br><br>
        <div>MLflow keeps track of many moving parts in your AI applications, such as models, prompts, tools, and code, with end-to-end lineage.</div><br>
        <a href="https://mlflow.org/docs/latest/genai/version-tracking/quickstart/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
  </tr>
</table>

### üéì For Data Scientists

<table>
  <tr>
    <td colspan="2" align="center" >
      <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-experiment.png" alt="Tracking" width=50%>
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/ml/tracking/"><strong>üìù Experiment Tracking</strong></a>
        <br><br>
        <div>Track your models, parameters, metrics, and evaluation results in ML experiments and compare them using an interactive UI.</div><br>
        <a href="https://mlflow.org/docs/latest/ml/tracking/quickstart/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
  </tr>
  <tr>
    <td>
      <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-model-registry.png" alt="Model Registry" width=100%>
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/ml/model-registry/"><strong>üíæ Model Registry</strong></a>
        <br><br>
        <div> A centralized model store designed to collaboratively manage the full lifecycle and deployment of machine learning models.</div><br>
        <a href="https://mlflow.org/docs/latest/ml/model-registry/tutorial/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
    <td>
      <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-deployment.png" alt="Deployment" width=100%>
    <div align="center">
        <br>
        <a href="https://mlflow.org/docs/latest/ml/deployment/"><strong>üöÄ Deployment</strong></a>
        <br><br>
        <div> Tools for seamless model deployment to batch and real-time scoring on platforms like Docker, Kubernetes, Azure ML, and AWS SageMaker.</div><br>
        <a href="https://mlflow.org/docs/latest/ml/deployment/">Getting Started ‚Üí</a>
        <br><br>
    </div>
    </td>
  </tr>
</table>

## üåê Hosting MLflow Anywhere

<div align="center" >
  <img src="https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-providers.png" alt="Providers" width=100%>
</div>

You can run MLflow in many different environments, including local machines, on-premise servers, and cloud infrastructure.

Trusted by thousands of organizations, MLflow is now offered as a managed service by most major cloud providers:

- [Amazon SageMaker](https://aws.amazon.com/sagemaker-ai/experiments/)
- [Azure ML](https://learn.microsoft.com/en-us/azure/machine-learning/concept-mlflow?view=azureml-api-2)
- [Databricks](https://www.databricks.com/product/managed-mlflow)
- [Nebius](https://nebius.com/services/managed-mlflow)

For hosting MLflow on your own infrastructure, please refer to [this guidance](https://mlflow.org/docs/latest/ml/tracking/#tracking-setup).

## üó£Ô∏è Supported Programming Languages

- [Python](https://pypi.org/project/mlflow/)
- [TypeScript / JavaScript](https://www.npmjs.com/package/mlflow-tracing)
- [Java](https://mvnrepository.com/artifact/org.mlflow/mlflow-client)
- [R](https://cran.r-project.org/web/packages/mlflow/readme/README.html)

## üîó Integrations

MLflow is natively integrated with many popular machine learning frameworks and GenAI libraries.

![Integrations](https://raw.githubusercontent.com/mlflow/mlflow/refs/heads/master/assets/readme-integrations.png)

## Usage Examples

### Tracing (Observability) ([Doc](https://mlflow.org/docs/latest/llms/tracing/index.html))

MLflow Tracing provides LLM observability for various GenAI libraries such as OpenAI, LangChain, LlamaIndex, DSPy, AutoGen, and more. To enable auto-tracing, call `mlflow.xyz.autolog()` before running your models. Refer to the documentation for customization and manual instrumentation.

```python
import mlflow
from openai import OpenAI

# Enable tracing for OpenAI
mlflow.openai.autolog()

# Query OpenAI LLM normally
response = OpenAI().chat.completions.create(
    model="gpt-4o-mini",
    messages=[{"role": "user", "content": "Hi!"}],
    temperature=0.1,
)
```

Then navigate to the "Traces" tab in the MLflow UI to find the trace records for the OpenAI query.

### Evaluating LLMs, Prompts, and Agents ([Doc](https://mlflow.org/docs/latest/genai/eval-monitor/index.html))

The following example runs automatic evaluation for question-answering tasks with several built-in metrics.

```python
import os
import openai
import mlflow
from mlflow.genai.scorers import Correctness, Guidelines

client = openai.OpenAI(api_key=os.getenv("OPENAI_API_KEY"))

# 1. Define a simple QA dataset
dataset = [
    {
        "inputs": {"question": "Can MLflow manage prompts?"},
        "expectations": {"expected_response": "Yes!"},
    },
    {
        "inputs": {"question": "Can MLflow create a taco for my lunch?"},
        "expectations": {
            "expected_response": "No, unfortunately, MLflow is not a taco maker."
        },
    },
]


# 2. Define a prediction function to generate responses
def predict_fn(question: str) -> str:
    response = client.chat.completions.create(
        model="gpt-4o-mini", messages=[{"role": "user", "content": question}]
    )
    return response.choices[0].message.content


# 3. Run the evaluation
results = mlflow.genai.evaluate(
    data=dataset,
    predict_fn=predict_fn,
    scorers=[
        # Built-in LLM judge
        Correctness(),
        # Custom criteria using LLM judge
        Guidelines(name="is_english", guidelines="The answer must be in English"),
    ],
)
```

Navigate to the "Evaluations" tab in the MLflow UI to find the evaluation results.

### Tracking Model Training ([Doc](https://mlflow.org/docs/latest/ml/tracking/))

The following example trains a simple regression model with scikit-learn, while enabling MLflow's [autologging](https://mlflow.org/docs/latest/tracking/autolog.html) feature for experiment tracking.

```python
import mlflow

from sklearn.model_selection import train_test_split
from sklearn.datasets import load_diabetes
from sklearn.ensemble import RandomForestRegressor

# Enable MLflow's automatic experiment tracking for scikit-learn
mlflow.sklearn.autolog()

# Load the training dataset
db = load_diabetes()
X_train, X_test, y_train, y_test = train_test_split(db.data, db.target)

rf = RandomForestRegressor(n_estimators=100, max_depth=6, max_features=3)
# MLflow triggers logging automatically upon model fitting
rf.fit(X_train, y_train)
```

Once the above code finishes, run the following command in a separate terminal and access the MLflow UI via the printed URL. An MLflow **Run** should be automatically created, which tracks the training dataset, hyperparameters, performance metrics, the trained model, dependencies, and even more.

```
mlflow server
```

## üí≠ Support

- For help or questions about MLflow usage (e.g. "how do I do X?") visit the [documentation](https://mlflow.org/docs/latest).
- In the documentation, you can ask the question to our AI-powered chat bot. Click on the **"Ask AI"** button at the right bottom.
- Join the [virtual events](https://lu.ma/mlflow?k=c) like office hours and meetups.
- To report a bug, file a documentation issue, or submit a feature request, please [open a GitHub issue](https://github.com/mlflow/mlflow/issues/new/choose).
- For release announcements and other discussions, please subscribe to our mailing list (mlflow-users@googlegroups.com)
  or join us on [Slack](https://mlflow.org/slack).

## ü§ù Contributing

We happily welcome contributions to MLflow!

- Submit [bug reports](https://github.com/mlflow/mlflow/issues/new?template=bug_report_template.yaml) and [feature requests](https://github.com/mlflow/mlflow/issues/new?template=feature_request_template.yaml)
- Contribute for [good-first-issues](https://github.com/mlflow/mlflow/issues?q=is%3Aissue+is%3Aopen+label%3A%22good+first+issue%22) and [help-wanted](https://github.com/mlflow/mlflow/issues?q=is%3Aissue+is%3Aopen+label%3A%22help+wanted%22)
- Writing about MLflow and sharing your experience

Please see our [contribution guide](CONTRIBUTING.md) to learn more about contributing to MLflow.

## ‚≠êÔ∏è Star History

<a href="https://star-history.com/#mlflow/mlflow&Date">
 <picture>
   <source media="(prefers-color-scheme: dark)" srcset="https://api.star-history.com/svg?repos=mlflow/mlflow&type=Date&theme=dark" />
   <source media="(prefers-color-scheme: light)" srcset="https://api.star-history.com/svg?repos=mlflow/mlflow&type=Date" />
   <img alt="Star History Chart" src="https://api.star-history.com/svg?repos=mlflow/mlflow&type=Date" />
 </picture>
</a>

## ‚úèÔ∏è Citation

If you use MLflow in your research, please cite it using the "Cite this repository" button at the top of the [GitHub repository page](https://github.com/mlflow/mlflow), which will provide you with citation formats including APA and BibTeX.

## üë• Core Members

MLflow is currently maintained by the following core members with significant contributions from hundreds of exceptionally talented community members.

- [Ben Wilson](https://github.com/BenWilson2)
- [Corey Zumar](https://github.com/dbczumar)
- [Daniel Lok](https://github.com/daniellok-db)
- [Gabriel Fu](https://github.com/gabrielfu)
- [Harutaka Kawamura](https://github.com/harupy)
- [Joel Robin P](https://github.com/joelrobin18)
- [Serena Ruan](https://github.com/serena-ruan)
- [Tomu Hirata](https://github.com/TomeHirata)
- [Weichen Xu](https://github.com/WeichenXu123)
- [Yuki Watanabe](https://github.com/B-Step62)
```

--------------------------------------------------------------------------------

---[FILE: SECURITY.md]---
Location: mlflow-master/SECURITY.md

```text
# Security Policy

MLflow and its community take security bugs seriously. We appreciate efforts to improve the security of MLflow
and follow the [GitHub coordinated disclosure of security vulnerabilities](https://docs.github.com/en/code-security/security-advisories/about-coordinated-disclosure-of-security-vulnerabilities#about-reporting-and-disclosing-vulnerabilities-in-projects-on-github)
for responsible disclosure and prompt mitigation. We are committed to working with security researchers to
resolve the vulnerabilities they discover.

## Supported Versions

The latest version of MLflow has continued support. If a critical vulnerability is found in the current version
of MLflow, we may opt to backport patches to previous versions.

## Reporting a Vulnerability

When finding a security vulnerability in MLflow, please perform the following actions:

- [Open an issue](https://github.com/mlflow/mlflow/issues/new?assignees=&labels=bug&template=bug_report_template.md&title=%5BBUG%5D%20Security%20Vulnerability) on the MLflow repository. Ensure that you use `[BUG] Security Vulnerability` as the title and _do not_ mention any vulnerability details in the issue post.
- Send a notification [email](mailto:mlflow-oss-maintainers@googlegroups.com) to `mlflow-oss-maintainers@googlegroups.com` that contains, at a minimum:
  - The link to the filed issue stub.
  - Your GitHub handle.
  - Detailed information about the security vulnerability, evidence that supports the relevance of the finding and any reproducibility instructions for independent confirmation.

This first stage of reporting is to ensure that a rapid validation can occur without wasting the time and effort of a reporter. Future communication and vulnerability resolution will be conducted after validating
the veracity of the reported issue.

An MLflow maintainer will, after validating the report:

- Acknowledge the [bug](ISSUE_POLICY.md#bug-reports) during [triage](ISSUE_TRIAGE.rst)
- Mark the issue as `priority/critical-urgent`
- Open a draft [GitHub Security Advisory](https://docs.github.com/en/code-security/security-advisories/creating-a-security-advisory)
  to discuss the vulnerability details in private.

The private Security Advisory will be used to confirm the issue, prepare a fix, and publicly disclose it after the fix has been released.
```

--------------------------------------------------------------------------------

---[FILE: settings.json]---
Location: mlflow-master/.claude/settings.json

```json
{
  "$schema": "https://json.schemastore.org/claude-code-settings.json",
  "hooks": {
    "PostToolUse": [
      {
        "matcher": "Edit|Write",
        "hooks": [
          {
            "type": "command",
            "command": "uv run --directory=$CLAUDE_PROJECT_DIR --no-project .claude/hooks/lint.py",
            "timeout": 10.0
          }
        ]
      }
    ]
  }
}
```

--------------------------------------------------------------------------------

---[FILE: pr-review.md]---
Location: mlflow-master/.claude/commands/pr-review.md

```text
---
allowed-tools: Read, Skill, Bash, Grep, Glob, mcp__review__fetch_diff, mcp__review__add_pr_review_comment
argument-hint: [extra_context]
description: Review a GitHub pull request and add review comments for issues found
---

# Review Pull Request

Automatically review a GitHub pull request and provide feedback on code quality, style guide violations, and potential bugs.

## Usage

```
/pr-review [extra_context]
```

## Arguments

- `extra_context` (optional): Additional instructions or filtering context (e.g., focus on specific issues or areas)

## Examples

```
/pr-review                                    # Review all changes
/pr-review Please focus on security issues    # Focus on security
/pr-review Only review Python files           # Filter specific file types
/pr-review Check for performance issues       # Focus on specific concern
```

## Instructions

### 1. Auto-detect PR context

- First check for environment variables:
  - If `PR_NUMBER` and `GITHUB_REPOSITORY` are set, parse `GITHUB_REPOSITORY` as `owner/repo` and use `PR_NUMBER`
  - Then use `gh pr view <PR_NUMBER> --repo <owner/repo> --json 'title,body'` to retrieve the PR title and description
- Otherwise:
  - Use `gh pr view --json 'title,body,url,number'` to get PR info for the current branch
  - Parse the output to extract owner, repo, PR number, title, and description
- If neither method works, inform the user that no PR was found and exit

### 2. Fetch PR Diff

- Use `mcp__review__fetch_diff` tool to fetch the PR diff
- **If reviewing Python files**: Read `dev/guides/python.md` and create a checklist of all style rules with their exceptions before proceeding

### 3. Review Changed Lines

**Apply additional filtering** from user instructions if provided (e.g., focus on specific issues or areas)

Carefully examine **only the changed lines** (added or modified) in the diff for:

- Style guide violations (using your checklist if Python files)
- Potential bugs and code quality issues
- Common mistakes

**Important**: Ignore unchanged/context lines and pre-existing code.

### 4. Decision Point

- If **no issues found** ‚Üí Output "No issues found" and exit successfully
- If **issues found** ‚Üí Continue to step 5

### 5. Add Review Comments

For each issue found, use `mcp__review__add_pr_review_comment` with:

**What to comment on:**

- **Only** lines marked as added (+) or modified in the diff
- Never unchanged context lines or pre-existing code

**How to write comments:**

- Use suggestion blocks (three backticks + "suggestion") for simple fixes that maintainers can apply with one click

  ````
  ```suggestion
  <corrected code here>
  ```
  ````

- Copy original indentation exactly in suggestion blocks
- For repetitive issues, leave one representative comment instead of flagging every instance
- Be specific about the issue and why it needs changing
- For bugs, explain the potential problem and suggested fix clearly
- End each comment with `ü§ñ Generated with Claude Code`

**Tool parameters:**

- Single-line comment: Set `subject_type` to `line`, specify `line`
- Multi-line comment: Set `subject_type` to `line`, specify both `start_line` and `line`
```

--------------------------------------------------------------------------------

---[FILE: resolve.md]---
Location: mlflow-master/.claude/commands/resolve.md

```text
---
allowed-tools: Skill, Read, Edit, Write, Glob, Grep, Bash
argument-hint: [extra_context]
description: Resolve PR review comments by fetching unresolved feedback and making necessary code changes
---

# Resolve PR Review Comments

Automatically fetch and address PR review comments. This command examines review feedback and makes necessary code changes to resolve the issues.

## Usage

```
/resolve [extra_context]
```

## Arguments

- `extra_context` (optional): Additional instructions or filtering context (e.g., focus on specific files or issue types)

## Examples

```
/resolve                                           # Address all unresolved PR comments
/resolve Focus on type hint issues only            # Filter specific comment types
/resolve Skip comments from automated bots         # Apply custom filtering
/resolve Only resolve comments in mlflow/tracking/ # Focus on specific directories
```

## Instructions

1. **Auto-detect PR context**:

   - First check for environment variables:
     - If `PR_NUMBER` and `GITHUB_REPOSITORY` are set, read them and parse `GITHUB_REPOSITORY` as `owner/repo` and use `PR_NUMBER` directly
     - Then use `gh pr view <PR_NUMBER> --repo <owner/repo> --json 'title,body'` to retrieve the PR title and description
   - Otherwise:
     - Use `gh pr view --json 'title,body,url,number'` to get PR info for the current branch
     - Parse the output to extract owner, repo, PR number, title, and description
   - If neither method works, inform the user that no PR was found and exit

2. **Fetch unresolved review comments**:

   - Invoke the `fetch-unresolved-comments` skill to get only unresolved review threads
   - If no unresolved comments are found, inform the user and exit

3. **Apply additional filtering** from user instructions if provided (e.g., focus on specific files or issue types)

4. For each unresolved review comment:

   - Read the file and surrounding code for context
   - Make minimal, precise changes to address the feedback
   - Follow project style guides (Python: see `dev/guides/python.md`)

5. After making all changes, commit them:

   - Stage changes: `git add .`
   - Create DCO-signed commit with this exact format:

     ```bash
     git commit -s -m "Address PR review comments

     ü§ñ Generated with Claude Code

     Co-Authored-By: Claude <noreply@anthropic.com>"
     ```

   - Handle any pre-commit hook failures (they may auto-fix formatting)
   - **DO NOT PUSH** the changes; just commit them locally
```

--------------------------------------------------------------------------------

````
