---
source_txt: fullstack_samples/zulip-main
converted_utc: 2025-12-18T13:06:13Z
part: 452
parts_total: 1290
---

# FULLSTACK CODE DATABASE SAMPLES zulip-main

## Verbatim Content (Part 452 of 1290)

````text
================================================================================
FULLSTACK SAMPLES CODE DATABASE (VERBATIM) - zulip-main
================================================================================
Generated: December 18, 2025
Source: fullstack_samples/zulip-main
================================================================================

NOTES:
- This output is verbatim because the source is user-owned.
- Large/binary files may be skipped by size/binary detection limits.

================================================================================

---[FILE: generate_secrets.py]---
Location: zulip-main/scripts/setup/generate_secrets.py
Signals: Django

```python
#!/usr/bin/env python3
# This tools generates /etc/zulip/zulip-secrets.conf
import json
import os
import sys
from contextlib import suppress

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(BASE_DIR)
from scripts.lib.setup_path import setup_path
from scripts.lib.zulip_tools import get_config, get_config_file

setup_path()

os.environ["DISABLE_MANDATORY_SECRET_CHECK"] = "True"
os.environ["DJANGO_SETTINGS_MODULE"] = "zproject.settings"

import argparse
import configparser
import uuid

from nacl.encoding import Base64Encoder
from nacl.public import PrivateKey

os.chdir(os.path.join(os.path.dirname(__file__), "..", ".."))

# Standard, 64-bit tokens
AUTOGENERATED_SETTINGS = [
    "avatar_salt",
    "rabbitmq_password",
    "shared_secret",
]


def random_string(cnt: int) -> str:
    # We do in-function imports so that we only do the expensive work
    # of importing cryptography modules when necessary.
    #
    # This helps optimize noop provision performance.
    from django.utils.crypto import get_random_string

    return get_random_string(cnt)


def random_token() -> str:
    # We do in-function imports so that we only do the expensive work
    # of importing cryptography modules when necessary.
    #
    # This helps optimize noop provision performance.
    import secrets

    return secrets.token_hex(32)


def generate_django_secretkey() -> str:
    """Secret key generation taken from Django's startproject.py"""

    # We do in-function imports so that we only do the expensive work
    # of importing cryptography modules when necessary.
    #
    # This helps optimize noop provision performance.
    from django.utils.crypto import get_random_string

    chars = "abcdefghijklmnopqrstuvwxyz0123456789!@#$%^&*(-_=+)"
    return get_random_string(50, chars)


def get_old_conf(output_filename: str) -> dict[str, str]:
    if not os.path.exists(output_filename) or os.path.getsize(output_filename) == 0:
        return {}

    secrets_file = configparser.RawConfigParser()
    secrets_file.read(output_filename)

    return dict(secrets_file.items("secrets"))


def generate_secrets(development: bool = False) -> None:
    if development:
        OUTPUT_SETTINGS_FILENAME = "zproject/dev-secrets.conf"
    else:
        OUTPUT_SETTINGS_FILENAME = "/etc/zulip/zulip-secrets.conf"
    current_conf = get_old_conf(OUTPUT_SETTINGS_FILENAME)

    lines: list[str] = []
    if len(current_conf) == 0:
        lines = ["[secrets]\n"]

    def need_secret(name: str) -> bool:
        return name not in current_conf

    def add_secret(name: str, value: str) -> None:
        lines.append(f"{name} = {value}\n")
        current_conf[name] = value

    for name in AUTOGENERATED_SETTINGS:
        if need_secret(name):
            add_secret(name, random_token())

    # These secrets are exclusive to a Zulip development environment.
    # We use PostgreSQL peer authentication by default in production,
    # and initial_password_salt is used to generate passwords for the
    # test/development database users.  See `manage.py
    # print_initial_password`.
    if development and need_secret("initial_password_salt"):
        add_secret("initial_password_salt", random_token())
    if development and need_secret("local_database_password"):
        add_secret("local_database_password", random_token())

    # We only need a secret if the database username does not match
    # the OS username, as identd auth works in that case.
    if get_config(
        get_config_file(), "postgresql", "database_user", "zulip"
    ) != "zulip" and need_secret("postgres_password"):
        add_secret("postgres_password", random_token())

    # The core Django SECRET_KEY setting, used by Django internally to
    # secure sessions.  If this gets changed, all users will be logged out.
    if need_secret("secret_key"):
        secret_key = generate_django_secretkey()
        add_secret("secret_key", secret_key)
        # To prevent Django ImproperlyConfigured error
        from zproject import settings

        settings.SECRET_KEY = secret_key

    # Secret key for the Camo HTTPS proxy.
    if need_secret("camo_key"):
        add_secret("camo_key", random_string(64))

    # We enable Altcha in development
    if development and need_secret("altcha_hmac"):
        add_secret("altcha_hmac", random_token())

    if not development:
        # The memcached_password and redis_password secrets are only
        # required/relevant in production.

        # Password for authentication to memcached.
        if need_secret("memcached_password"):
            # We defer importing settings unless we need it, because
            # importing settings is expensive (mostly because of
            # django-auth-ldap) and we want the noop case to be fast.
            from zproject import settings

            if settings.MEMCACHED_LOCATION == "127.0.0.1:11211":
                add_secret("memcached_password", random_token())

        # Password for authentication to Redis.
        if need_secret("redis_password"):
            # We defer importing settings unless we need it, because
            # importing settings is expensive (mostly because of
            # django-auth-ldap) and we want the noop case to be fast.
            from zproject import settings

            if settings.REDIS_HOST == "127.0.0.1":
                # To prevent Puppet from restarting Redis, which would lose
                # data because we configured Redis to disable persistence, set
                # the Redis password on the running server and edit the config
                # file directly.

                import redis

                from zerver.lib.redis_utils import get_redis_client

                redis_password = random_token()

                for filename in ["/etc/redis/zuli-redis.conf", "/etc/redis/zulip-redis.conf"]:
                    if os.path.exists(filename):
                        with open(filename, "a") as f:
                            f.write(
                                "# Set a Redis password based on zulip-secrets.conf\n"
                                f"requirepass '{redis_password}'\n",
                            )
                        break

                with suppress(redis.exceptions.ConnectionError):
                    get_redis_client().config_set("requirepass", redis_password)

                add_secret("redis_password", redis_password)

    # Random id and secret used to identify this installation when
    # accessing the Zulip mobile push notifications service.
    # * zulip_org_key is generated using os.urandom().
    # * zulip_org_id only needs to be unique, so we use a UUID.
    if need_secret("zulip_org_key"):
        add_secret("zulip_org_key", random_string(64))
    if need_secret("zulip_org_id"):
        add_secret("zulip_org_id", str(uuid.uuid4()))

    if development and need_secret("push_registration_encryption_keys"):
        # 'settings.ZILENCER_ENABLED' would be a better check than
        # 'development' for whether we need push bouncer secrets,
        # but we're trying to avoid importing settings.
        private_key = PrivateKey.generate()
        private_key_str = Base64Encoder.encode(bytes(private_key)).decode("utf-8")
        public_key_str = Base64Encoder.encode(bytes(private_key.public_key)).decode("utf-8")
        add_secret(
            "push_registration_encryption_keys", json.dumps({public_key_str: private_key_str})
        )

    if len(lines) == 0:
        print("generate_secrets: No new secrets to generate.")
        return

    with open(OUTPUT_SETTINGS_FILENAME, "a") as f:
        # Write a newline at the start, in case there was no newline at
        # the end of the file due to human editing.
        f.write("\n" + "".join(lines))

    print(f"Generated new secrets in {OUTPUT_SETTINGS_FILENAME}.")


if __name__ == "__main__":
    parser = argparse.ArgumentParser()
    group = parser.add_mutually_exclusive_group(required=True)
    group.add_argument(
        "--development", action="store_true", help="For setting up the developer env for zulip"
    )
    group.add_argument(
        "--production",
        action="store_false",
        dest="development",
        help="For setting up the production env for zulip",
    )
    results = parser.parse_args()

    generate_secrets(results.development)
```

--------------------------------------------------------------------------------

---[FILE: initialize-database]---
Location: zulip-main/scripts/setup/initialize-database

```text
#!/usr/bin/env bash
set -e

usage() {
    echo "usage: initialize-database [--quiet]" >&2
    exit 1
}

args="$(getopt -o '' --long help,quiet -- "$@")"
eval "set -- $args"
while true; do
    case "$1" in
        --help) usage ;;
        --quiet)
            QUIET=1
            shift
            ;;
        --)
            shift
            break
            ;;
        *) usage ;;
    esac
done

if [ "$#" -gt 0 ]; then
    usage
fi

set -x

# Change to root directory of the checkout that we're running from
THIS_DIR="$(dirname "$(readlink -f "$0")")"
cd "$THIS_DIR/../.."

./manage.py migrate --noinput
./manage.py createcachetable third_party_api_results

# Check if the supervisor socket exists.  If not, it could be:
#
# A) A normal installation went bad (supervisor hasn't started)
# B) We are in a Docker container and don't have supervisor running
#
# In either case, it doesn't make sense to restart supervisor jobs
if [ -e "/var/run/supervisor.sock" ]; then
    ./scripts/restart-server
fi

set +x
if [ -z "$QUIET" ]; then
    echo "Congratulations!  You have successfully configured your Zulip database."
    echo "If you haven't already, you should configure email in /etc/zulip/settings.py."
    echo
    echo "Next, run as the zulip user (use 'su zulip' if needed):"
    echo
    echo "    /home/zulip/deployments/current/manage.py generate_realm_creation_link"
    echo
    echo "This generates a secure, single-use link that you can use to set up "
    echo "a Zulip organization from the convenience of your web browser."
fi
```

--------------------------------------------------------------------------------

---[FILE: install]---
Location: zulip-main/scripts/setup/install

```text
#!/usr/bin/env bash
#
# Thin wrapper around the actual install script (scripts/lib/install).
# The purpose of this wrapper is to log the full install script output
# to /var/log/zulip/install.log for easy debugging.

set -e
if [ "$EUID" -ne 0 ]; then
    echo "Error: The installation script must be run as root." >&2
    exit 1
fi
umask 022
mkdir -p /var/log/zulip

"$(dirname "$(dirname "$0")")/lib/install" "$@" 2>&1 | tee -a /var/log/zulip/install.log
failed=${PIPESTATUS[0]}

if [ "$failed" -ne 0 ]; then
    echo -e '\033[0;31m'
    echo "Zulip installation failed (exit code $failed)!"
    echo
    echo -n "The install process is designed to be idempotent, so you can retry "
    echo -n "after resolving whatever issue caused the failure (there should be a traceback above). "
    echo -n "A log of this installation is available in /var/log/zulip/install.log"
    echo -e '\033[0m'
    exit "$failed"
fi
```

--------------------------------------------------------------------------------

---[FILE: pgroonga-config]---
Location: zulip-main/scripts/setup/pgroonga-config

```text
#!/usr/bin/env bash
set -eux

dbversion=$(crudini --get /etc/zulip/zulip.conf postgresql version)
dbname=$(crudini --get /etc/zulip/zulip.conf postgresql database_name 2>/dev/null || echo zulip)

if ! su postgres -c "psql -At -c 'SELECT datname FROM pg_database WHERE NOT datistemplate'" | grep -Fx "$dbname"; then
    echo "No database to install into!"
    exit 0
fi

sharedir="${1:-/usr/share/postgresql/$dbversion}"
applied_file="$sharedir/pgroonga_setup.sql.applied"

installed_version=$(dpkg-query --show --showformat='${Version}' "postgresql-$dbversion-pgdg-pgroonga")

if [ ! -f "$applied_file" ]; then
    sql="CREATE EXTENSION PGROONGA"
else
    sql="ALTER EXTENSION pgroonga UPDATE"
fi

echo "$sql" | su postgres -c "psql -v ON_ERROR_STOP=1 $dbname"

echo "$installed_version" >"$applied_file"
```

--------------------------------------------------------------------------------

---[FILE: reindex-textual-data]---
Location: zulip-main/scripts/setup/reindex-textual-data

```text
#!/usr/bin/env python3

import argparse
import logging
import os
import sys
import time

sys.path.append(os.path.join(os.path.dirname(__file__), "../.."))
from scripts.lib.setup_path import setup_path

setup_path()

import psycopg2
import psycopg2.extensions
from psycopg2.sql import SQL, Identifier

from scripts.lib.zulip_tools import su_to_zulip

su_to_zulip()
os.environ["DJANGO_SETTINGS_MODULE"] = "zproject.settings"
from django.conf import settings

parser = argparse.ArgumentParser(
    description="Reindex all text indexes, for glibc upgrades.  This will take a write lock on every table, unless --concurrently is passed."
)
parser.add_argument(
    "--concurrently", action="store_true", help="reindex concurrently, on Pg â‰¥ 11; takes longer"
)
parser.add_argument("--force", action="store_true", help="run the reindexing")
options = parser.parse_args()

logging.Formatter.converter = time.gmtime
logging.basicConfig(format="%(asctime)s %(levelname)s: %(message)s")
logger = logging.getLogger("reindex-textual-data")
logger.setLevel(logging.DEBUG)

pg_args = {}
pg_args["host"] = settings.DATABASES["default"]["HOST"]
pg_args["port"] = settings.DATABASES["default"].get("PORT")
pg_args["password"] = settings.DATABASES["default"].get("PASSWORD")
pg_args["user"] = settings.DATABASES["default"]["USER"]
pg_args["dbname"] = settings.DATABASES["default"]["NAME"]
pg_args["sslmode"] = settings.DATABASES["default"]["OPTIONS"].get("sslmode")
pg_args["connect_timeout"] = "600"

# connection_factory=None lets mypy understand the return type
conn = psycopg2.connect(connection_factory=None, **pg_args)
conn.autocommit = True

cursor = conn.cursor()
cursor.execute(
    """
SELECT
        irel.relname AS index_name,
        trel.relname AS table_name,
        pg_size_pretty(pg_table_size(i.indrelid)) AS size
FROM
        pg_index AS i
        JOIN pg_class AS trel ON trel.oid = i.indrelid
        JOIN pg_namespace AS tnsp ON trel.relnamespace = tnsp.oid
        JOIN pg_class AS irel ON irel.oid = i.indexrelid
        JOIN pg_attribute AS a ON a.attrelid = i.indexrelid
        WHERE tnsp.nspname = 'zulip'
        AND a.attcollation != 0
GROUP BY 1, 2, i.indrelid
ORDER BY pg_table_size(i.indrelid) ASC
"""
)
reindex_targets = cursor.fetchall()

if not options.force:
    print("Would reindex the following indexes:")
    for index, _, _ in reindex_targets:
        print(f"  {index}")
    print(
        """

Re-run with --force to reindex these.  Without --concurrently, these
index rebuilds will TAKE A WRITE LOCK on their respective tables,
which means that production traffic will be affected.

On PostgreSQL 11 and above, you can pass --concurrently, which will do
the index rebuilds without taking such a lock. We recommend only using
--concurrently if the Zulip server will be serving traffic while
running this tool, because concurrent reindexing takes longer to
complete even if the server is not running.
"""
    )
    sys.exit(0)

had_failures = False
for index_name, table_name, index_size in reindex_targets:
    if options.concurrently:
        command = SQL("REINDEX INDEX CONCURRENTLY {}").format(Identifier(index_name))
    else:
        command = SQL("REINDEX INDEX {}").format(Identifier(index_name))

    logger.info("%s -- on %s, %s", command, table_name, index_size)
    try:
        cursor.execute(command)
    except psycopg2.OperationalError as e:
        logger.warning("Failed to reindex %s: %s", index_name, e)
        had_failures = True

if not had_failures:
    sys.exit(0)

print(
    """
=========================> REINDEXING FAILED <=========================

Reindexing failed on one or more indexes; this is generally caused
by duplicate rows that had been incorrectly inserted because of
corrupted database indexes.  This happens, for example, when glibc was
upgraded to 2.28 or higher, which has a different ordering of text
("collation") than earlier versions.  Because of the new ordering,
entries in the indexes are not found (because they exist in a
different place), which results in duplicates being created in the
database for columns which should be unique.

There is no generalized tool to fix these duplicate rows, but in most cases
the database can be repaired with some manual work.  We are using
this chat.zulip.org for support around such repairs:

  https://chat.zulip.org/#narrow/channel/31-production-help/topic/database.20corruption

This tool has regenerated all database indexes that do not have duplicate rows.
Once you have manually repaired duplicate rows, you can rerun this command
to regenerate the rest.

It is reasonable to run your Zulip server to avoid downtime while you
plan the manual repair work. Additional duplicate rows may be created
for any corrupted index that has not yet been regenerated. But any new
duplicate rows will be similar to existing duplicate rows that you
already need to manually repair.
    """
)
sys.exit(1)
```

--------------------------------------------------------------------------------

---[FILE: restore-backup]---
Location: zulip-main/scripts/setup/restore-backup

```text
#!/usr/bin/env python3
import argparse
import os
import re
import subprocess
import sys
import tempfile
from typing import IO

BASE_DIR = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(BASE_DIR)
from scripts.lib.zulip_tools import assert_running_as_root, get_postgres_pwent, run, su_to_zulip

POSTGRES_PWENT = get_postgres_pwent()

parser = argparse.ArgumentParser()
parser.add_argument("tarball", help="Filename of input tarball")
parser.add_argument(
    "--keep-settings", help="Do not overwrite local /etc/zulip/settings.py", action="store_true"
)
parser.add_argument(
    "--keep-zulipconf", help="Do not overwrite local /etc/zulip/zulip.conf", action="store_true"
)


def restore_backup(tarball_file: IO[bytes], keep_settings: bool, keep_zulipconf: bool) -> None:
    assert_running_as_root()
    su_to_zulip(save_suid=True)

    from scripts.lib.setup_path import setup_path

    setup_path()

    # First, we unpack the /etc/zulip configuration, so we know how
    # this server is supposed to be configured (and can import
    # /etc/zulip/settings.py via `from django.conf import settings`,
    # next).  Ignore errors if zulip-backup/settings is not present
    # (E.g. because this is a development backup).
    tarball_file.seek(0, 0)
    excludes = []
    if keep_settings:
        excludes += ["--exclude=settings.py"]
    if keep_zulipconf:
        excludes += ["--exclude=zulip.conf"]
    run(
        [
            "tar",
            "--directory=/etc/zulip",
            *excludes,
            "--strip-components=2",
            "-xz",
            "zulip-backup/settings",
        ],
        stdin=tarball_file,
    )

    os.environ["DJANGO_SETTINGS_MODULE"] = "zproject.settings"
    from django.conf import settings

    paths = [
        # zproject will only be present for development environment backups.
        ("zproject", os.path.join(settings.DEPLOY_ROOT, "zproject")),
    ]
    if settings.LOCAL_UPLOADS_DIR is not None:
        # We only need to restore LOCAL_UPLOADS_DIR if the system is
        # configured to locally host uploads.
        paths.append(("uploads", os.path.join(settings.DEPLOY_ROOT, settings.LOCAL_UPLOADS_DIR)))

    with tempfile.TemporaryDirectory(prefix="zulip-restore-backup-") as tmp:
        uid = os.getuid()
        gid = os.getgid()
        os.setresuid(0, 0, 0)
        for name, path in paths:
            os.makedirs(path, exist_ok=True)
            os.chown(path, uid, gid)
        os.setresuid(uid, uid, 0)

        assert not any("|" in name or "|" in path for name, path in paths)
        transform_args = [
            r"--transform=s|^zulip-backup/{}(/.*)?$|{}\1|x".format(
                re.escape(name),
                path.replace("\\", r"\\"),
            )
            for name, path in paths
        ]

        os.mkdir(os.path.join(tmp, "zulip-backup"))
        tarball_file.seek(0, 0)
        run(["tar", "-C", tmp, *transform_args, "-xPz"], stdin=tarball_file)

        # Now, extract the database backup, destroy the old
        # database, and create a new, empty database.
        db = settings.DATABASES["default"]
        assert isinstance(db["NAME"], str)
        db_dir = os.path.join(tmp, "zulip-backup", "database")
        os.setresuid(0, 0, 0)
        run(["chown", "-R", POSTGRES_PWENT.pw_name, "--", tmp])
        os.setresuid(POSTGRES_PWENT.pw_uid, POSTGRES_PWENT.pw_uid, 0)

        postgresql_env = dict(os.environ)
        if db["HOST"] not in ["", "localhost"]:
            postgresql_env["PGHOST"] = db["HOST"]
            if "PORT" in db:
                postgresql_env["PGPORT"] = db["PORT"]
            postgresql_env["PGUSER"] = db["USER"]
            if "PASSWORD" in db:
                postgresql_env["PGPASSWORD"] = db["PASSWORD"]

        run(
            [
                os.path.join(settings.DEPLOY_ROOT, "scripts", "setup", "terminate-psql-sessions"),
                db["NAME"],
            ],
            env=postgresql_env,
        )
        run(["dropdb", "--if-exists", "--", db["NAME"]], cwd="/", env=postgresql_env)
        run(
            ["createdb", "--owner=zulip", "--template=template0", "--", db["NAME"]],
            cwd="/",
            env=postgresql_env,
        )
        os.setresuid(0, 0, 0)

        if settings.PRODUCTION:
            # In case we are restoring a backup from an older Zulip
            # version, there may be new secrets to generate.
            run(
                [
                    os.path.join(settings.DEPLOY_ROOT, "scripts", "setup", "generate_secrets.py"),
                    "--production",
                ]
            )

            # If there is a local RabbitMQ, we need to reconfigure it
            # to ensure the RabbitMQ password matches the value in the
            # restored zulip-secrets.conf.  We need to be careful to
            # only do this if RabbitMQ is configured to run locally on
            # the system.
            rabbitmq_host = subprocess.check_output(
                [
                    os.path.join(settings.DEPLOY_ROOT, "scripts", "get-django-setting"),
                    "RABBITMQ_HOST",
                ],
                text=True,
            ).strip()
            if rabbitmq_host in ["127.0.0.1", "::1", "localhost", "localhost6"]:
                run([os.path.join(settings.DEPLOY_ROOT, "scripts", "setup", "configure-rabbitmq")])

            # In production, we also need to do a `zulip-puppet-apply`
            # in order to apply any configuration from
            # /etc/zulip/zulip.conf to this system, since it was
            # originally installed without the restored copy of that
            # file.
            run([os.path.join(settings.DEPLOY_ROOT, "scripts", "zulip-puppet-apply"), "-f"])

        # Now, restore the database backup using pg_restore.  This
        # needs to run after zulip-puppet-apply to ensure full-text
        # search extensions are available and installed.
        os.setresuid(POSTGRES_PWENT.pw_uid, POSTGRES_PWENT.pw_uid, 0)
        run(["pg_restore", "--dbname=" + db["NAME"], "--", db_dir], cwd="/", env=postgresql_env)
        os.setresuid(0, 0, 0)
        run(["chown", "-R", str(uid), "--", tmp])
        os.setresuid(uid, uid, 0)

        if settings.PRODUCTION:
            run([os.path.join(settings.DEPLOY_ROOT, "scripts", "restart-server")])

        run([os.path.join(settings.DEPLOY_ROOT, "scripts", "setup", "flush-memcached")])


if __name__ == "__main__":
    args = parser.parse_args()

    with open(args.tarball, "rb") as tarball_file:
        restore_backup(tarball_file, args.keep_settings, args.keep_zulipconf)
```

--------------------------------------------------------------------------------

---[FILE: setup-certbot]---
Location: zulip-main/scripts/setup/setup-certbot

```text
#!/usr/bin/env bash

set -e

usage() {
    cat <<EOF >&2
Usage: $0 --email=admin@example.com [--method={webroot|standalone}] \
hostname.example.com [another.example.com]
EOF
    exit 1
}

if [ "$EUID" -ne 0 ]; then
    echo "Error: This script must be run as root" >&2
    exit 1
fi

method=webroot
args="$(getopt -o '' --long help,email:,method:,agree-tos -n "$0" -- "$@")"
eval "set -- $args"
agree_tos=()
while true; do
    case "$1" in
        --email)
            EMAIL="$2"
            shift
            shift
            ;;
        --method)
            method="$2"
            shift
            shift
            ;;
        --agree-tos)
            agree_tos=(--agree-tos)
            shift
            ;;
        --help)
            show_help=1
            shift
            ;;
        --)
            shift
            break
            ;;
    esac
done

# Parse the remaining arguments as Subject Alternative Names to pass to certbot
HOSTNAMES=()
for arg; do
    HOSTNAMES+=(-d "$arg")
done
DOMAIN=$1

if [ -n "$show_help" ]; then
    usage
fi

if [ -z "$DOMAIN" ] || [ -z "$EMAIL" ]; then
    usage
fi

case "$method" in
    standalone)
        method_args=(--standalone --no-directory-hooks)
        ;;
    webroot)
        method_args=(--webroot '--webroot-path=/var/lib/zulip/certbot-webroot/')
        ;;
    *)
        usage
        ;;
esac

# If we aren't being run interactively, default to keeping the
# existing certificate (rather than burning through a renewal)
# If run interactively, certbot will prompt.
default_keep=()
if [ ! -t 0 ]; then
    default_keep=(--keep-until-expiring)
fi

# We need to know _which_ domain is Zulip's, in the symlink deploy
# hook, so we pass this down
export ZULIP_DOMAIN="$DOMAIN"

# Certbot does not run deploy hooks on new certificates
# (certbot/certbot#9978) so we will need to fake it if so
if [ -d "/etc/letsencrypt/live/$DOMAIN/" ]; then
    needs_hooks=0
else
    needs_hooks=1
fi

certbot certonly "${method_args[@]}" \
    "${HOSTNAMES[@]}" -m "$EMAIL" \
    "${agree_tos[@]}" \
    "${default_keep[@]}" \
    --no-eff-email

# "certbot certonly" before version 3.2.0 does not run deploy hooks,
# so we fake running them.
if [ "$needs_hooks" = "1" ]; then
    export RENEWED_DOMAINS="$*"
    if [ "$method" == "webroot" ]; then
        for deploy_hook in /etc/letsencrypt/renewal-hooks/deploy/*; do
            "$deploy_hook"
        done
    fi
fi
echo "Certbot SSL certificate configuration succeeded."
```

--------------------------------------------------------------------------------

---[FILE: sha256-file-to]---
Location: zulip-main/scripts/setup/sha256-file-to

```text
#!/bin/sh

if [ "$#" -ne 3 ]; then
    echo "Usage:"
    echo "  sha256-file-to SHA256 http://FETCH/FROM DST"
    echo
    echo "SHA256 is the sha256sum of the file fetched; the file is"
    echo "placed in DST."
    exit 1
fi

set -e
set -x

SHA256="$1"
URL="$2"
DST="$3"

# Work in a tmpdir which we clean up at the end
tmpdir="$(mktemp -d)"
trap 'rm -r "$tmpdir"' EXIT
cd "$tmpdir"

# Fetch to a predictable name, not whatever curl guesses from the URL
LOCALFILE="output"
curl -fL --retry 3 -o "$LOCALFILE" "$URL"

# Check the hash against what was passed in
echo "$SHA256  $LOCALFILE" >"$LOCALFILE.sha256"
sha256sum -c "$LOCALFILE.sha256"

mv "$LOCALFILE" "$DST"
```

--------------------------------------------------------------------------------

---[FILE: sha256-tarball-to]---
Location: zulip-main/scripts/setup/sha256-tarball-to

```text
#!/usr/bin/env bash

if [ "$#" -lt 4 ]; then
    echo "Usage:"
    echo "  sha256-tarball-to SHA256 http://FETCH/FROM.tar.gz SRC1 DST1 [SRC2 DST2 [...]]"
    echo
    echo "SHA256 is the sha256sum of the tarball fetched; each SRC (which may be a"
    echo "directory) is expected to be a relative path into the unpacked tarball,"
    echo "and each DST is the absolute path it should be moved to."
    exit 1
fi

set -e
set -x

SHA256="$1"
URL="$2"
shift
shift

# Work in a tmpdir which we clean up at the end
tmpdir="$(mktemp -d)"
trap 'rm -r "$tmpdir"' EXIT
cd "$tmpdir"

# We support both .tar.gz and .zip files
if [[ "$URL" == *.tar.gz ]] || [[ "$URL" == *.tgz ]]; then
    extension="tar.gz"
elif [[ "$URL" == *.zip ]]; then
    extension="zip"
else
    echo "Can't determine archive type from URL: $URL"
    exit 1
fi

# Fetch to a predictable name, not whatever curl guesses from the URL
LOCALFILE="archive.$extension"
curl -fL --retry 3 -o "$LOCALFILE" "$URL"

# Check the hash against what was passed in
echo "$SHA256  $LOCALFILE" >"$LOCALFILE.sha256"
sha256sum -c "$LOCALFILE.sha256"

if [[ "$extension" == "tar.gz" ]]; then
    tar xzf "$LOCALFILE"
else
    unzip "$LOCALFILE"
fi

# Take the rest of the arguments two-at-a-time, as source and
# destination to move out of the unpacked tarball.
while [ "$#" -gt 0 ]; do
    mv "$1" "$2"
    shift
    shift
done
```

--------------------------------------------------------------------------------

---[FILE: terminate-psql-sessions]---
Location: zulip-main/scripts/setup/terminate-psql-sessions

```text
#!/usr/bin/env bash
set -e

cd /

tables="$(printf "'%s'," "${@//\'/\'\'}")"
tables="${tables%,}"

psql postgres -v ON_ERROR_STOP=1 <<EOF
SELECT pg_terminate_backend(s.pid)
    FROM pg_stat_activity s, pg_roles r
    WHERE
        s.datname IN ($tables)
        AND r.rolname = CURRENT_USER
        AND (s.usename = r.rolname OR r.rolsuper = 't')
        AND s.pid <> pg_backend_pid();
EOF
```

--------------------------------------------------------------------------------

---[FILE: upgrade-postgresql]---
Location: zulip-main/scripts/setup/upgrade-postgresql

```text
#!/usr/bin/env bash
set -euo pipefail

if [ "$EUID" -ne 0 ]; then
    echo "Error: This script must be run as root" >&2
    exit 1
fi

# Force a known locale; some OS X terminals set an invalid LC_CTYPE
# which crashes pg_upgradecluster
export LC_ALL=C.UTF-8
export LANG=C.UTF-8
export LANGUAGE=C.UTF-8

LATEST_SUPPORTED_VERSION=18
UPGRADE_TO=${1:-$LATEST_SUPPORTED_VERSION}
UPGRADE_FROM=$(crudini --get /etc/zulip/zulip.conf postgresql version)
ZULIP_PATH="$(dirname "$0")/../.."

if [ "$UPGRADE_TO" = "$UPGRADE_FROM" ]; then
    echo "Already running PostgreSQL $UPGRADE_TO!"
    exit 1
fi

if [[ "$UPGRADE_TO" -lt "$UPGRADE_FROM" ]]; then
    echo "Refusing to downgrade PostgreSQL $UPGRADE_FROM to $UPGRADE_TO!"
    exit 1
fi

if [[ "$UPGRADE_TO" -gt "$LATEST_SUPPORTED_VERSION" ]]; then
    echo "This version of Zulip does not support PostgreSQL $UPGRADE_TO."
    echo "You may need to upgrade Zulip before you can upgrade to PostgreSQL $UPGRADE_TO."
    exit 1
fi

# Verify that the version in /etc/zulip/zulip.conf is the version that
# Django actually stores its data in.  We can only do that if the
# database server is on the same host as the application server.
if [ -d /home/zulip/deployments/current ]; then
    DATA_IS_IN=$(
        su -s /usr/bin/env -- zulip \
            DJANGO_SETTINGS_MODULE=zproject.settings \
            uv run --directory=/home/zulip/deployments/current --no-sync \
            python -c 'from django.db import connection; print(connection.cursor().connection.server_version // 10000)'
    )

    if [ "$UPGRADE_FROM" != "$DATA_IS_IN" ]; then
        cat <<EOF

/etc/zulip/zulip.conf claims that Zulip is running PostgreSQL
$UPGRADE_FROM, but the server is connected to a PostgreSQL running
version $DATA_IS_IN.  Check the output from pg_lsclusters to verify
which clusters are running, and update /etc/zulip/zulip.conf to match.

In general, this results from manually upgrading PostgreSQL; you
should use this tool for all PostgreSQL upgrades.
EOF
        exit 1
    fi
fi

set -x

"$ZULIP_PATH"/scripts/lib/setup-apt-repo
apt-get install -y "postgresql-$UPGRADE_TO" "postgresql-client-$UPGRADE_TO"
drop_main_cluster="$(
    pg_lsclusters --json \
        | jq --arg pg_version "$UPGRADE_TO" -r \
            '.[] | select((.version|tostring == $ARGS.named.pg_version) and (.cluster == "main")) | .cluster'
)"
if [ -n "$drop_main_cluster" ]; then
    pg_dropcluster "$UPGRADE_TO" main --stop
fi

(
    # Two-stage application of Puppet; we apply the bare-bones
    # PostgreSQL configuration first, so that FTS will be configured
    # prior to the pg_upgradecluster.
    TEMP_CONF_DIR=$(mktemp -d)
    cp /etc/zulip/zulip.conf "$TEMP_CONF_DIR"
    ZULIP_CONF="${TEMP_CONF_DIR}/zulip.conf"
    crudini --set "$ZULIP_CONF" postgresql version "$UPGRADE_TO"

    if [ -f "/usr/share/postgresql/$UPGRADE_FROM/pgroonga_setup.sql.applied" ]; then
        # This file is intentionally blank, to trigger always running
        # `ALTER EXTENSION pgroonga UPDATE` and not `CREATE EXTENSION pgroonga`.
        touch "/usr/share/postgresql/$UPGRADE_TO/pgroonga_setup.sql.applied"
    fi

    "$ZULIP_PATH"/scripts/zulip-puppet-apply -f --config "$ZULIP_CONF" --tags postgresql_upgrade
    rm -rf "$TEMP_CONF_DIR"
)

# Capture the output so we know where the path to the post-upgrade scripts is
UPGRADE_LOG=$(mktemp "/var/log/zulip/upgrade-postgresql-$UPGRADE_FROM-$UPGRADE_TO.XXXXXXXXX.log")
pg_upgradecluster -v "$UPGRADE_TO" "$UPGRADE_FROM" main --method=upgrade --link --no-start | tee "$UPGRADE_LOG"
SCRIPTS_PATH=$(grep -o "/var/log/postgresql/pg_upgradecluster-$UPGRADE_FROM-$UPGRADE_TO-main.*" "$UPGRADE_LOG" || true)

# If the upgrade completed successfully, lock in the new version in
# our configuration immediately
crudini --set /etc/zulip/zulip.conf postgresql version "$UPGRADE_TO"

# Make sure the new PostgreSQL is running
pg_ctlcluster "$UPGRADE_TO" main start

# Update the statistics
su postgres -c "/usr/lib/postgresql/$UPGRADE_TO/bin/vacuumdb --all --analyze-only --jobs 10"

# Update extensions
if [ -n "$SCRIPTS_PATH" ] && [ -f "$SCRIPTS_PATH/update_extensions.sql" ]; then
    su postgres -c "psql $SCRIPTS_PATH/update_extensions.sql"
    rm "$SCRIPTS_PATH/update_extensions.sql"
fi

# Start the database up cleanly
"$ZULIP_PATH"/scripts/zulip-puppet-apply -f

# Drop the old data, binaries, and scripts
pg_dropcluster "$UPGRADE_FROM" main
apt remove -y "postgresql-$UPGRADE_FROM"
if [ -n "$SCRIPTS_PATH" ] && [ -f "$SCRIPTS_PATH/delete_old_cluster.sh" ]; then
    su postgres -c "$SCRIPTS_PATH/delete_old_cluster.sh"
    rm "$SCRIPTS_PATH/delete_old_cluster.sh"
fi

if [ -n "$SCRIPTS_PATH" ]; then
    if [ -n "$(ls -A "$SCRIPTS_PATH")" ]; then
        set +x
        echo
        echo
        echo ">>>>> pg_upgradecluster succeeded, but unexpected post-upgrade scripts"
        echo "      were found:"
        ls -A1 "$SCRIPTS_PATH"
    else
        rmdir "$SCRIPTS_PATH"
    fi
else
    set +x
    echo
    echo
    echo ">>>>> pg_upgradecluster succeeded, but post-upgrade scripts path could not"
    echo "      be parsed out!  Please read the pg_upgradecluster output to understand"
    echo "      the current status of your cluster:"
    echo "          $UPGRADE_LOG"
    echo "      and report this bug with the PostgreSQL $UPGRADE_FROM -> $UPGRADE_TO upgrade to:"
    echo "          https://github.com/zulip/zulip/issues"
    echo
    echo
fi
```

--------------------------------------------------------------------------------

---[FILE: jammy.list]---
Location: zulip-main/scripts/setup/apt-repos/ksplice/jammy.list

```text
deb [signed-by=/etc/apt/keyrings/ksplice.asc] http://www.ksplice.com/apt jammy ksplice
deb-src [signed-by=/etc/apt/keyrings/ksplice.asc] http://www.ksplice.com/apt jammy ksplice
```

--------------------------------------------------------------------------------

---[FILE: ksplice.asc]---
Location: zulip-main/scripts/setup/apt-repos/ksplice/ksplice.asc

```text
-----BEGIN PGP PUBLIC KEY BLOCK-----
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=Y2MU
-----END PGP PUBLIC KEY BLOCK-----
```

--------------------------------------------------------------------------------

---[FILE: noble.list]---
Location: zulip-main/scripts/setup/apt-repos/ksplice/noble.list

```text
deb [signed-by=/etc/apt/keyrings/ksplice.asc] http://www.ksplice.com/apt noble ksplice
deb-src [signed-by=/etc/apt/keyrings/ksplice.asc] http://www.ksplice.com/apt noble ksplice
```

--------------------------------------------------------------------------------

---[FILE: jammy.list]---
Location: zulip-main/scripts/setup/apt-repos/teleport/jammy.list

```text
deb [signed-by=/etc/apt/keyrings/teleport-pubkey.asc] https://apt.releases.teleport.dev/ubuntu jammy stable/v17
```

--------------------------------------------------------------------------------

````
