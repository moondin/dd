---
source_txt: fullstack_samples/mlflow-master
converted_utc: 2025-12-18T11:25:54Z
part: 703
parts_total: 991
---

# FULLSTACK CODE DATABASE SAMPLES mlflow-master

## Verbatim Content (Part 703 of 991)

````text
================================================================================
FULLSTACK SAMPLES CODE DATABASE (VERBATIM) - mlflow-master
================================================================================
Generated: December 18, 2025
Source: fullstack_samples/mlflow-master
================================================================================

NOTES:
- This output is verbatim because the source is user-owned.
- Large/binary files may be skipped by size/binary detection limits.

================================================================================

---[FILE: constant.py]---
Location: mlflow-master/mlflow/tracing/constant.py

```python
from enum import Enum


# NB: These keys are placeholders and subject to change
class TraceMetadataKey:
    INPUTS = "mlflow.traceInputs"
    OUTPUTS = "mlflow.traceOutputs"
    SOURCE_RUN = "mlflow.sourceRun"
    MODEL_ID = "mlflow.modelId"
    # Trace size statistics including total size, number of spans, and max span size
    SIZE_STATS = "mlflow.trace.sizeStats"
    # Aggregated token usage information in a single trace, stored as a dumped JSON string.
    TOKEN_USAGE = "mlflow.trace.tokenUsage"
    # Store the user ID/name of the application request. Do not confuse this with mlflow.user
    # tag, which stores "who created the trace" i.e. developer or system name.
    TRACE_USER = "mlflow.trace.user"
    # Store the session ID of the application request.
    TRACE_SESSION = "mlflow.trace.session"

    # Total size of the trace in bytes. Deprecated, use SIZE_STATS instead.
    SIZE_BYTES = "mlflow.trace.sizeBytes"


class TraceTagKey:
    TRACE_NAME = "mlflow.traceName"
    EVAL_REQUEST_ID = "mlflow.eval.requestId"
    SPANS_LOCATION = "mlflow.trace.spansLocation"
    # Store the source scorer name that generated the trace. This tag is used to determine if a
    # trace is generated by a scorer or prediction during evaluation and filter out the scorer
    # traces in the UI. This supposed to be immutable, but we use tag because we can only set this
    # after the scorer is executed, which is not possible with trace metadata.
    SOURCE_SCORER_NAME = "mlflow.trace.sourceScorer"
    # Store a list of linked prompt versions in JSON format
    # Structure: [{"name": "prompt_name", "version": "version"}]
    LINKED_PROMPTS = "mlflow.linkedPrompts"


class TokenUsageKey:
    """Key for the token usage information in the `mlflow.chat.tokenUsage` span attribute."""

    INPUT_TOKENS = "input_tokens"
    OUTPUT_TOKENS = "output_tokens"
    TOTAL_TOKENS = "total_tokens"

    @classmethod
    def all_keys(cls):
        return [cls.INPUT_TOKENS, cls.OUTPUT_TOKENS, cls.TOTAL_TOKENS]


class TraceSizeStatsKey:
    TOTAL_SIZE_BYTES = "total_size_bytes"
    NUM_SPANS = "num_spans"
    MAX_SPAN_SIZE_BYTES = "max"
    P25_SPAN_SIZE_BYTES = "p25"
    P50_SPAN_SIZE_BYTES = "p50"
    P75_SPAN_SIZE_BYTES = "p75"


# A set of reserved attribute keys
class SpanAttributeKey:
    EXPERIMENT_ID = "mlflow.experimentId"
    REQUEST_ID = "mlflow.traceRequestId"
    INPUTS = "mlflow.spanInputs"
    OUTPUTS = "mlflow.spanOutputs"
    SPAN_TYPE = "mlflow.spanType"
    FUNCTION_NAME = "mlflow.spanFunctionName"
    START_TIME_NS = "mlflow.spanStartTimeNs"
    CHAT_TOOLS = "mlflow.chat.tools"
    # This attribute is used to store token usage information from LLM responses.
    # Stored in {"input_tokens": int, "output_tokens": int, "total_tokens": int} format.
    CHAT_USAGE = "mlflow.chat.tokenUsage"
    # This attribute indicates which flavor/format generated the LLM span. This is
    # used by downstream (e.g., UI) to determine the message format for parsing.
    MESSAGE_FORMAT = "mlflow.message.format"
    # This attribute is used to populate `intermediate_outputs` property of a trace data
    # representing intermediate outputs of the trace. This attribute is not empty only on
    # the root span of a trace created by the `mlflow.log_trace` API. The `intermediate_outputs`
    # property of the normal trace is generated by the outputs of non-root spans.
    INTERMEDIATE_OUTPUTS = "mlflow.trace.intermediate_outputs"
    # This attribute is used to store prompt version information when load_prompt is called
    # within an active span. Stored as a JSON list of {"name": "...", "version": "..."} objects,
    # same format as LINKED_PROMPTS_TAG_KEY in traces.
    LINKED_PROMPTS = "mlflow.linkedPrompts"


class AssessmentMetadataKey:
    # When the assessment is generated by an eval run, log the run ID here.
    SOURCE_RUN_ID = "mlflow.assessment.sourceRunId"
    # Total LLM cost spent for generating the feedback (llm-as-a-judge).
    JUDGE_COST = "mlflow.assessment.judgeCost"
    # When the scorer generates a trace for assessment scoring, log the trace ID here.
    SCORER_TRACE_ID = "mlflow.assessment.scorerTraceId"


# All storage backends are guaranteed to support request_metadata key/value up to 250 characters
MAX_CHARS_IN_TRACE_INFO_METADATA = 250
# All storage backends are guaranteed to support tag keys up to 250 characters,
# values up to 4096 characters
MAX_CHARS_IN_TRACE_INFO_TAGS_KEY = 250
MAX_CHARS_IN_TRACE_INFO_TAGS_VALUE = 4096
TRUNCATION_SUFFIX = "..."

TRACE_REQUEST_RESPONSE_PREVIEW_MAX_LENGTH_DBX = 10000
TRACE_REQUEST_RESPONSE_PREVIEW_MAX_LENGTH_OSS = 1000

# Trace request ID must have the prefix "tr-" appended to the OpenTelemetry trace ID
TRACE_REQUEST_ID_PREFIX = "tr-"
# Trace ID V4 format starts with "trace:/" in the format of "trace:/<location>/<trace_id>"
TRACE_ID_V4_PREFIX = "trace:/"

# Schema version of traces and spans.
TRACE_SCHEMA_VERSION = 3

# Key for the trace schema version in the trace. This key is also used in
# Databricks model serving to be careful when modifying it.
TRACE_SCHEMA_VERSION_KEY = "mlflow.trace_schema.version"


STREAM_CHUNK_EVENT_NAME_FORMAT = "mlflow.chunk.item.{index}"
STREAM_CHUNK_EVENT_VALUE_KEY = "mlflow.chunk.value"


# Key for Databricks model serving options to return the trace in the response
DATABRICKS_OPTIONS_KEY = "databricks_options"
RETURN_TRACE_OPTION_KEY = "return_trace"
DATABRICKS_OUTPUT_KEY = "databricks_output"

# Assessment constants
ASSESSMENT_ID_PREFIX = "a-"


# Maximum number of seconds to retry getting a trace from the v4 endpoint.
# V4 traces have some delay in propagation after the log_spans call returns success response.
# To make sure get_trace API does not fail due to this delay, we retry up to a reasonable timeout.
# Setting 15 seconds because the initial version of the backend is known to have 1~5 seconds delay.
GET_TRACE_V4_RETRY_TIMEOUT_SECONDS = 15


# The location of the spans in the trace.
# This is used to determine where the spans are stored when exporting.
class SpansLocation(str, Enum):
    TRACKING_STORE = "TRACKING_STORE"
    ARTIFACT_REPO = "ARTIFACT_REPO"


# Path to the notebook trace renderer directory
TRACE_RENDERER_ASSET_PATH = "/static-files/lib/notebook-trace-renderer"
```

--------------------------------------------------------------------------------

---[FILE: databricks.py]---
Location: mlflow-master/mlflow/tracing/databricks.py

```python
from mlflow.exceptions import MlflowException
from mlflow.utils.annotations import experimental
from mlflow.utils.uri import is_databricks_uri


@experimental(version="3.5.0")
def set_databricks_monitoring_sql_warehouse_id(
    sql_warehouse_id: str, experiment_id: str | None = None
) -> None:
    """
    Set the SQL warehouse ID used for Databricks production monitoring on traces logged to the given
    MLflow experiment. This only has an effect for experiments with UC schema as trace location.

    Args:
        sql_warehouse_id: The SQL warehouse ID to use for monitoring.
        experiment_id: The MLflow experiment ID. If not provided, the current active experiment
            will be used.
    """
    from mlflow.entities import ExperimentTag
    from mlflow.tracking import get_tracking_uri
    from mlflow.tracking._tracking_service.utils import _get_store
    from mlflow.tracking.fluent import _get_experiment_id

    tracking_uri = get_tracking_uri()
    if not is_databricks_uri(tracking_uri):
        raise MlflowException(
            "This function is only supported when the tracking URI is set to 'databricks'. "
            f"Current tracking URI: {tracking_uri}"
        )

    resolved_experiment_id = experiment_id or _get_experiment_id()

    if not resolved_experiment_id:
        raise MlflowException(
            "No experiment ID provided and no active experiment found. "
            "Please provide an experiment_id or set an active experiment "
            "using mlflow.set_experiment()."
        )

    store = _get_store()
    store.set_experiment_tag(
        resolved_experiment_id,
        ExperimentTag("mlflow.monitoring.sqlWarehouseId", sql_warehouse_id),
    )
```

--------------------------------------------------------------------------------

---[FILE: destination.py]---
Location: mlflow-master/mlflow/tracing/destination.py

```python
"""
Trace destination classes are DEPRECATED. Use mlflow.entities.trace_location.TraceLocation instead.
"""

from __future__ import annotations

import logging
from contextvars import ContextVar
from dataclasses import dataclass

import mlflow
from mlflow.entities.trace_location import (
    MlflowExperimentLocation,
    TraceLocationBase,
    UCSchemaLocation,
)
from mlflow.environment_variables import MLFLOW_TRACING_DESTINATION
from mlflow.exceptions import MlflowException
from mlflow.utils.annotations import deprecated

_logger = logging.getLogger(__name__)


class UserTraceDestinationRegistry:
    def __init__(self):
        self._global_value = None
        self._context_local_value = ContextVar("mlflow_trace_destination", default=None)

    def get(self) -> TraceLocationBase | None:
        """First check the context-local value, then the global value."""
        if local_destination := self._context_local_value.get():
            return local_destination
        return self._global_value or self._get_trace_location_from_env()

    def set(self, value, context_local: bool = False):
        if context_local:
            self._context_local_value.set(value)
        else:
            self._global_value = value

    def reset(self):
        self._global_value = None
        self._context_local_value.set(None)

    def _get_trace_location_from_env(self) -> TraceLocationBase | None:
        """
        Get trace location from `MLFLOW_TRACING_DESTINATION` environment variable.
        """
        if location := MLFLOW_TRACING_DESTINATION.get():
            match location.split("."):
                case [catalog_name, schema_name]:
                    if (
                        mlflow.get_tracking_uri() is None
                        or not mlflow.get_tracking_uri().startswith("databricks")
                    ):
                        mlflow.set_tracking_uri("databricks")
                        _logger.info(
                            "Automatically setting the tracking URI to `databricks` "
                            "because the tracing destination is set to Databricks."
                        )
                    return UCSchemaLocation(catalog_name, schema_name)
                case [experiment_id]:
                    return MlflowExperimentLocation(experiment_id)
                case _:
                    raise MlflowException.invalid_parameter_value(
                        f"Failed to parse trace location {location} rom MLFLOW_TRACING_DESTINATION "
                        "environment variable. Expected format: <catalog_name>.<schema_name> or "
                        "<experiment_id>"
                    )
        return None


@deprecated(since="3.5.0", alternative="mlflow.entities.trace_location.TraceLocation")
@dataclass
class TraceDestination:
    """A configuration object for specifying the destination of trace data."""

    @property
    def type(self) -> str:
        """Type of the destination."""
        raise NotImplementedError

    def to_location(self) -> TraceLocationBase:
        raise NotImplementedError


@deprecated(since="3.5.0", alternative="mlflow.entities.trace_location.MlflowExperimentLocation")
@dataclass
class MlflowExperiment(TraceDestination):
    """
    A destination representing an MLflow experiment.

    By setting this destination in the :py:func:`mlflow.tracing.set_destination` function,
    MLflow will log traces to the specified experiment.

    Attributes:
        experiment_id: The ID of the experiment to log traces to. If not specified,
            the current active experiment will be used.
    """

    experiment_id: str | None = None

    @property
    def type(self) -> str:
        return "experiment"

    def to_location(self) -> TraceLocationBase:
        return MlflowExperimentLocation(experiment_id=self.experiment_id)


@deprecated(since="3.5.0", alternative="mlflow.entities.trace_location.MlflowExperimentLocation")
@dataclass
class Databricks(TraceDestination):
    """
    A destination representing a Databricks tracing server.

    By setting this destination in the :py:func:`mlflow.tracing.set_destination` function,
    MLflow will log traces to the specified experiment.

    If neither experiment_id nor experiment_name is specified, an active experiment
    when traces are created will be used as the destination.
    If both are specified, they must refer to the same experiment.

    Attributes:
        experiment_id: The ID of the experiment to log traces to.
        experiment_name: The name of the experiment to log traces to.
    """

    experiment_id: str | None = None
    experiment_name: str | None = None

    def __post_init__(self):
        if self.experiment_id is not None:
            self.experiment_id = str(self.experiment_id)

        if self.experiment_name is not None:
            from mlflow.tracking._tracking_service.utils import _get_store

            # NB: Use store directly rather than fluent API to avoid dependency on MLflowClient
            experiment_id = _get_store().get_experiment_by_name(self.experiment_name).experiment_id
            if self.experiment_id is not None and self.experiment_id != experiment_id:
                raise MlflowException.invalid_parameter_value(
                    "experiment_id and experiment_name must refer to the same experiment"
                )
            self.experiment_id = experiment_id

    @property
    def type(self) -> str:
        return "databricks"

    def to_location(self) -> TraceLocationBase:
        return MlflowExperimentLocation(experiment_id=self.experiment_id)
```

--------------------------------------------------------------------------------

---[FILE: enablement.py]---
Location: mlflow-master/mlflow/tracing/enablement.py

```python
"""
Trace enablement functionality for MLflow to enable tracing to Databricks Storage.
"""

import logging

import mlflow
from mlflow.entities.trace_location import UCSchemaLocation
from mlflow.exceptions import MlflowException
from mlflow.utils.annotations import experimental
from mlflow.utils.uri import is_databricks_uri
from mlflow.version import IS_TRACING_SDK_ONLY

_logger = logging.getLogger(__name__)


@experimental(version="3.5.0")
def set_experiment_trace_location(
    location: UCSchemaLocation,
    experiment_id: str | None = None,
    sql_warehouse_id: str | None = None,
) -> UCSchemaLocation:
    """
    Configure the storage location for traces of an experiment.

    Unity Catalog tables for storing trace data will be created in the specified schema.
    When tracing is enabled, all traces for the specified experiment will be
    stored in the provided Unity Catalog schema.

    .. note::

        If the experiment is already linked to a storage location, this will raise an error.
        Use `mlflow.tracing.unset_experiment_trace_location` to remove the existing storage
        location first and then set a new one.

    Args:
        location: The storage location for experiment traces in Unity Catalog.
        experiment_id: The MLflow experiment ID to set the storage location for.
            If not specified, the current active experiment will be used.
        sql_warehouse_id: SQL warehouse ID for creating views and querying.
            If not specified, uses the value from MLFLOW_TRACING_SQL_WAREHOUSE_ID,
            fallback to the default SQL warehouse if the environment variable is not set.

    Returns:
        The UCSchemaLocation object representing the configured storage location, including
        the table names of the spans and logs tables.

    Example:

        .. code-block:: python

            import mlflow
            from mlflow.entities import UCSchemaLocation

            location = UCSchemaLocation(catalog_name="my_catalog", schema_name="my_schema")

            result = mlflow.tracing.set_experiment_trace_location(
                location=location,
                experiment_id="12345",
            )
            print(result.full_otel_spans_table_name)  # my_catalog.my_schema.otel_spans_table


            @mlflow.trace
            def add(x):
                return x + 1


            add(1)  # this writes the trace to the storage location set above

    """
    from mlflow.tracing.client import TracingClient
    from mlflow.tracking import get_tracking_uri
    from mlflow.tracking.fluent import _get_experiment_id

    if not is_databricks_uri(get_tracking_uri()):
        raise MlflowException(
            "The `set_experiment_trace_location` API is only supported on Databricks."
        )

    experiment_id = experiment_id or _get_experiment_id()
    if experiment_id is None:
        raise MlflowException.invalid_parameter_value(
            "Experiment ID is required to set storage location, either pass it as an argument or "
            "use `mlflow.set_experiment` to set the current experiment."
        )

    # Check if the experiment exists. In Databricks notebook, this `get_experiment` call triggers
    # a side effect to create the experiment for the notebook if it doesn't exist. This side effect
    # is convenient for users.
    if experiment_id and not IS_TRACING_SDK_ONLY:
        try:
            mlflow.get_experiment(str(experiment_id))
        except Exception as e:
            raise MlflowException.invalid_parameter_value(
                f"Could not find experiment with ID {experiment_id}. Please make sure the "
                "experiment exists before setting the storage location."
            ) from e

    uc_schema_location = TracingClient()._set_experiment_trace_location(
        location=location,
        experiment_id=experiment_id,
        sql_warehouse_id=sql_warehouse_id,
    )

    _logger.info(
        f"Successfully configured storage location for experiment `{experiment_id}` to "
        f"Databricks storage at {uc_schema_location}"
    )

    return uc_schema_location


@experimental(version="3.5.0")
def unset_experiment_trace_location(
    location: UCSchemaLocation,
    experiment_id: str | None = None,
) -> None:
    """
    Unset the storage location for traces of an experiment.

    This function removes the experiment storage location configuration,
    including the view and the experiment tag.

    Args:
        location: The storage location to unset.
        experiment_id: The MLflow experiment ID to unset the storage location for. If not provided,
            the current active experiment will be used.

    Example:

        .. code-block:: python

            import mlflow
            from mlflow.entities import UCSchemaLocation

            mlflow.tracing.unset_experiment_trace_location(
                location=UCSchemaLocation(catalog_name="my_catalog", schema_name="my_schema"),
                experiment_id="12345",
            )

    """
    from mlflow.tracing.client import TracingClient
    from mlflow.tracking import get_tracking_uri
    from mlflow.tracking.fluent import _get_experiment_id

    if not is_databricks_uri(get_tracking_uri()):
        raise MlflowException(
            "The `unset_experiment_trace_location` API is only supported on Databricks."
        )

    if not isinstance(location, UCSchemaLocation):
        raise MlflowException.invalid_parameter_value(
            "`location` must be an instance of `mlflow.entities.UCSchemaLocation`."
        )
    experiment_id = experiment_id or _get_experiment_id()
    if experiment_id is None:
        raise MlflowException.invalid_parameter_value(
            "Experiment ID is required to clear storage location, either pass it as an argument or "
            "use `mlflow.set_experiment` to set the current experiment."
        )
    TracingClient()._unset_experiment_trace_location(experiment_id, location)
    _logger.info(f"Successfully cleared storage location for experiment `{experiment_id}`")
```

--------------------------------------------------------------------------------

````
